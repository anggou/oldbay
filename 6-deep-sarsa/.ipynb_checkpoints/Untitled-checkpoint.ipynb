{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e92a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "PhotoImage = ImageTk.PhotoImage\n",
    "UNIT = 50  # 픽셀 수\n",
    "HEIGHT = 5  # 그리드 세로\n",
    "WIDTH = 5  # 그리드 가로\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "class Env(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super(Env, self).__init__()\n",
    "        self.action_space = ['u', 'd', 'l', 'r']\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.title('DeepSARSA')\n",
    "        self.geometry('{0}x{1}'.format(HEIGHT * UNIT, HEIGHT * UNIT))\n",
    "        self.shapes = self.load_images()\n",
    "        self.canvas = self._build_canvas()\n",
    "        self.counter = 0\n",
    "        self.rewards = []\n",
    "        self.goal = []\n",
    "        # 장애물 설정\n",
    "        self.set_reward([0, 1], -1)\n",
    "        self.set_reward([1, 2], -1)\n",
    "        self.set_reward([2, 3], -1)\n",
    "        # 목표 지점 설정\n",
    "        self.set_reward([4, 4], 1)\n",
    "\n",
    "    def _build_canvas(self):\n",
    "        canvas = tk.Canvas(self, bg='white',\n",
    "                           height=HEIGHT * UNIT,\n",
    "                           width=WIDTH * UNIT)\n",
    "        # 그리드 생성\n",
    "        for c in range(0, WIDTH * UNIT, UNIT):  # 0~400 by 80\n",
    "            x0, y0, x1, y1 = c, 0, c, HEIGHT * UNIT\n",
    "            canvas.create_line(x0, y0, x1, y1)\n",
    "        for r in range(0, HEIGHT * UNIT, UNIT):  # 0~400 by 80\n",
    "            x0, y0, x1, y1 = 0, r, HEIGHT * UNIT, r\n",
    "            canvas.create_line(x0, y0, x1, y1)\n",
    "\n",
    "        self.rewards = []\n",
    "        self.goal = []\n",
    "        # 캔버스에 이미지 추가\n",
    "        x, y = UNIT/2, UNIT/2\n",
    "        self.rectangle = canvas.create_image(x, y, image=self.shapes[0])\n",
    "\n",
    "        canvas.pack()\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def load_images(self):\n",
    "        rectangle = PhotoImage(\n",
    "            Image.open(\"../img/rectangle.png\").resize((30, 30)))\n",
    "        triangle = PhotoImage(\n",
    "            Image.open(\"../img/triangle.png\").resize((30, 30)))\n",
    "        circle = PhotoImage(\n",
    "            Image.open(\"../img/circle.png\").resize((30, 30)))\n",
    "\n",
    "        return rectangle, triangle, circle\n",
    "\n",
    "    def reset_reward(self):\n",
    "\n",
    "        for reward in self.rewards:\n",
    "            self.canvas.delete(reward['figure'])\n",
    "\n",
    "        self.rewards.clear()\n",
    "        self.goal.clear()\n",
    "        self.set_reward([0, 1], -1)\n",
    "        self.set_reward([1, 2], -1)\n",
    "        self.set_reward([2, 3], -1)\n",
    "\n",
    "        # #goal\n",
    "        self.set_reward([4, 4], 1)\n",
    "\n",
    "    def set_reward(self, state, reward):\n",
    "        state = [int(state[0]), int(state[1])]\n",
    "        x = int(state[0])\n",
    "        y = int(state[1])\n",
    "        temp = {}\n",
    "        if reward > 0:\n",
    "            temp['reward'] = reward\n",
    "            temp['figure'] = self.canvas.create_image((UNIT * x) + UNIT / 2,\n",
    "                                                       (UNIT * y) + UNIT / 2,\n",
    "                                                       image=self.shapes[2])\n",
    "\n",
    "            self.goal.append(temp['figure'])\n",
    "\n",
    "\n",
    "        elif reward < 0:\n",
    "            temp['direction'] = -1\n",
    "            temp['reward'] = reward\n",
    "            temp['figure'] = self.canvas.create_image((UNIT * x) + UNIT / 2,\n",
    "                                                      (UNIT * y) + UNIT / 2,\n",
    "                                                      image=self.shapes[1])\n",
    "\n",
    "        temp['coords'] = self.canvas.coords(temp['figure'])\n",
    "        temp['state'] = state\n",
    "        self.rewards.append(temp)\n",
    "\n",
    "    # new methods\n",
    "\n",
    "    def check_if_reward(self, state):\n",
    "        check_list = dict()\n",
    "        check_list['if_goal'] = False\n",
    "        rewards = 0\n",
    "\n",
    "        for reward in self.rewards:\n",
    "            if reward['state'] == state:\n",
    "                rewards += reward['reward']\n",
    "                if reward['reward'] == 1:\n",
    "                    check_list['if_goal'] = True\n",
    "\n",
    "        check_list['rewards'] = rewards\n",
    "\n",
    "        return check_list\n",
    "\n",
    "    def coords_to_state(self, coords):\n",
    "        x = int((coords[0] - UNIT / 2) / UNIT)\n",
    "        y = int((coords[1] - UNIT / 2) / UNIT)\n",
    "        return [x, y]\n",
    "\n",
    "    def reset(self):\n",
    "        self.update()\n",
    "        time.sleep(0.5)\n",
    "        x, y = self.canvas.coords(self.rectangle)\n",
    "        self.canvas.move(self.rectangle, UNIT / 2 - x, UNIT / 2 - y)\n",
    "        self.reset_reward()\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.counter += 1\n",
    "        self.render()\n",
    "\n",
    "        if self.counter % 2 == 1:\n",
    "            self.rewards = self.move_rewards()\n",
    "\n",
    "        next_coords = self.move(self.rectangle, action)\n",
    "        check = self.check_if_reward(self.coords_to_state(next_coords))\n",
    "        done = check['if_goal']\n",
    "        reward = check['rewards']\n",
    "\n",
    "        self.canvas.tag_raise(self.rectangle)\n",
    "\n",
    "        s_ = self.get_state()\n",
    "\n",
    "        return s_, reward, done\n",
    "\n",
    "    def get_state(self):\n",
    "\n",
    "        location = self.coords_to_state(self.canvas.coords(self.rectangle))\n",
    "        agent_x = location[0]\n",
    "        agent_y = location[1]\n",
    "\n",
    "        states = list()\n",
    "\n",
    "        for reward in self.rewards:\n",
    "            reward_location = reward['state']\n",
    "            states.append(reward_location[0] - agent_x)\n",
    "            states.append(reward_location[1] - agent_y)\n",
    "            if reward['reward'] < 0:\n",
    "                states.append(-1)\n",
    "                states.append(reward['direction'])\n",
    "            else:\n",
    "                states.append(1)\n",
    "\n",
    "        return states\n",
    "\n",
    "    def move_rewards(self):\n",
    "        new_rewards = []\n",
    "        for temp in self.rewards:\n",
    "            if temp['reward'] == 1:\n",
    "                new_rewards.append(temp)\n",
    "                continue\n",
    "            temp['coords'] = self.move_const(temp)\n",
    "            temp['state'] = self.coords_to_state(temp['coords'])\n",
    "            new_rewards.append(temp)\n",
    "        return new_rewards\n",
    "\n",
    "    def move_const(self, target):\n",
    "\n",
    "        s = self.canvas.coords(target['figure'])\n",
    "\n",
    "        base_action = np.array([0, 0])\n",
    "\n",
    "        if s[0] == (WIDTH - 1) * UNIT + UNIT / 2:\n",
    "            target['direction'] = 1\n",
    "        elif s[0] == UNIT / 2:\n",
    "            target['direction'] = -1\n",
    "\n",
    "        if target['direction'] == -1:\n",
    "            base_action[0] += UNIT\n",
    "        elif target['direction'] == 1:\n",
    "            base_action[0] -= UNIT\n",
    "\n",
    "        if (target['figure'] is not self.rectangle\n",
    "           and s == [(WIDTH - 1) * UNIT, (HEIGHT - 1) * UNIT]):\n",
    "            base_action = np.array([0, 0])\n",
    "\n",
    "        self.canvas.move(target['figure'], base_action[0], base_action[1])\n",
    "\n",
    "        s_ = self.canvas.coords(target['figure'])\n",
    "\n",
    "        return s_\n",
    "\n",
    "    def move(self, target, action):\n",
    "        s = self.canvas.coords(target)\n",
    "\n",
    "        base_action = np.array([0, 0])\n",
    "\n",
    "        if action == 0:  # 상\n",
    "            if s[1] > UNIT:\n",
    "                base_action[1] -= UNIT\n",
    "        elif action == 1:  # 하\n",
    "            if s[1] < (HEIGHT - 1) * UNIT:\n",
    "                base_action[1] += UNIT\n",
    "        elif action == 2:  # 우\n",
    "            if s[0] < (WIDTH - 1) * UNIT:\n",
    "                base_action[0] += UNIT\n",
    "        elif action == 3:  # 좌\n",
    "            if s[0] > UNIT:\n",
    "                base_action[0] -= UNIT\n",
    "\n",
    "        self.canvas.move(target, base_action[0], base_action[1])\n",
    "\n",
    "        s_ = self.canvas.coords(target)\n",
    "\n",
    "        return s_\n",
    "\n",
    "    def render(self):\n",
    "        # 게임 속도 조정\n",
    "        time.sleep(0.05)\n",
    "        self.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5028af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 155       \n",
      "=================================================================\n",
      "Total params: 1,565\n",
      "Trainable params: 1,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: -17 global_step 133   epsilon: 0.9867873979365388\n",
      "episode: 1   score: -2 global_step 173   epsilon: 0.9828479355460494\n",
      "episode: 2   score: -15 global_step 357   epsilon: 0.9649280064714622\n",
      "episode: 3   score: -12 global_step 448   epsilon: 0.9561865584476045\n",
      "episode: 4   score: -19 global_step 695   epsilon: 0.9328568914851036\n",
      "episode: 5   score: -13 global_step 805   epsilon: 0.9226511896576549\n",
      "episode: 6   score: -17 global_step 975   epsilon: 0.9070979191478462\n",
      "episode: 7   score: -4 global_step 1013   epsilon: 0.9036573163078697\n",
      "episode: 8   score: -9 global_step 1108   epsilon: 0.8951127953095525\n",
      "episode: 9   score: -2 global_step 1129   epsilon: 0.8932349369863083\n",
      "episode: 10   score: -4 global_step 1168   epsilon: 0.8897579314470128\n",
      "episode: 11   score: -8 global_step 1239   epsilon: 0.8834627098505575\n",
      "episode: 12   score: -3 global_step 1294   epsilon: 0.8786167612200774\n",
      "episode: 13   score: -9 global_step 1331   epsilon: 0.87537172397014\n",
      "episode: 14   score: 1 global_step 1374   epsilon: 0.8716155193715681\n",
      "episode: 15   score: -8 global_step 1411   epsilon: 0.8683963401425531\n",
      "episode: 16   score: -4 global_step 1458   epsilon: 0.8643242506427495\n",
      "episode: 17   score: -7 global_step 1583   epsilon: 0.8535869088357361\n",
      "episode: 18   score: -10 global_step 1712   epsilon: 0.8426458124523126\n",
      "episode: 19   score: -2 global_step 1742   epsilon: 0.8401215371054063\n",
      "episode: 20   score: 1 global_step 1760   epsilon: 0.838610603039286\n",
      "episode: 21   score: 1 global_step 1776   epsilon: 0.8372698319376778\n",
      "episode: 22   score: -3 global_step 1797   epsilon: 0.8355133224441879\n",
      "episode: 23   score: -5 global_step 1836   epsilon: 0.8322610040114864\n",
      "episode: 24   score: -5 global_step 1880   epsilon: 0.8286069177717583\n",
      "episode: 25   score: -20 global_step 1991   epsilon: 0.8194597841345723\n",
      "episode: 26   score: 0 global_step 2010   epsilon: 0.8179042110272086\n",
      "episode: 27   score: 0 global_step 2027   epsilon: 0.8165148856622092\n",
      "episode: 28   score: -2 global_step 2050   epsilon: 0.8146389657625221\n",
      "episode: 29   score: -1 global_step 2081   epsilon: 0.8121173693806092\n",
      "episode: 30   score: -4 global_step 2163   epsilon: 0.8054849055902344\n",
      "episode: 31   score: -5 global_step 2229   epsilon: 0.8001859460635561\n",
      "episode: 32   score: 1 global_step 2247   epsilon: 0.7987468349924324\n",
      "episode: 33   score: -6 global_step 2311   epsilon: 0.7936509247563761\n",
      "episode: 34   score: -2 global_step 2339   epsilon: 0.7914316995691779\n",
      "episode: 35   score: -12 global_step 2406   epsilon: 0.7861465678839923\n",
      "episode: 36   score: 0 global_step 2424   epsilon: 0.7847327062247952\n",
      "episode: 37   score: -4 global_step 2511   epsilon: 0.7779348055278205\n",
      "episode: 38   score: 0 global_step 2528   epsilon: 0.7766133738209482\n",
      "episode: 39   score: -4 global_step 2591   epsilon: 0.7717358460311793\n",
      "episode: 40   score: -5 global_step 2653   epsilon: 0.7669656481665864\n",
      "episode: 41   score: -3 global_step 2681   epsilon: 0.7648210409708602\n",
      "episode: 42   score: 0 global_step 2723   epsilon: 0.7616153689363544\n",
      "episode: 43   score: -5 global_step 2768   epsilon: 0.7581956289723096\n",
      "episode: 44   score: -1 global_step 2790   epsilon: 0.7565293488534068\n",
      "episode: 45   score: -1 global_step 2820   epsilon: 0.7542630486400774\n",
      "episode: 46   score: -3 global_step 2839   epsilon: 0.752831237906886\n",
      "episode: 47   score: -1 global_step 2855   epsilon: 0.7516276109022719\n",
      "episode: 48   score: -3 global_step 2879   epsilon: 0.7498257776078169\n",
      "episode: 49   score: 0 global_step 2896   epsilon: 0.7485520930392382\n",
      "episode: 50   score: 0 global_step 2912   epsilon: 0.7473553075338344\n",
      "episode: 51   score: 0 global_step 2940   epsilon: 0.7452655352289961\n",
      "episode: 52   score: -2 global_step 2968   epsilon: 0.7431816063941132\n",
      "episode: 53   score: -2 global_step 3008   epsilon: 0.7402146694492194\n",
      "episode: 54   score: 0 global_step 3031   epsilon: 0.738514047142335\n",
      "episode: 55   score: -2 global_step 3057   epsilon: 0.7365963088713853\n",
      "episode: 56   score: -1 global_step 3075   epsilon: 0.7352715619069324\n",
      "episode: 57   score: -5 global_step 3101   epsilon: 0.7333622435679438\n",
      "episode: 58   score: -2 global_step 3116   epsilon: 0.7322629698993681\n",
      "episode: 59   score: -1 global_step 3153   epsilon: 0.7295584680972701\n",
      "episode: 60   score: -1 global_step 3202   epsilon: 0.7259921977852374\n",
      "episode: 61   score: -2 global_step 3220   epsilon: 0.7246865220050994\n",
      "episode: 62   score: -2 global_step 3237   epsilon: 0.7234555399987465\n",
      "episode: 63   score: -5 global_step 3263   epsilon: 0.7215769049453516\n",
      "episode: 64   score: -1 global_step 3278   epsilon: 0.720495296915465\n",
      "episode: 65   score: -1 global_step 3313   epsilon: 0.7179778456114062\n",
      "episode: 66   score: -8 global_step 3384   epsilon: 0.7128980036906729\n",
      "episode: 67   score: 0 global_step 3409   epsilon: 0.7111178957366935\n",
      "episode: 68   score: -2 global_step 3432   epsilon: 0.709484122446015\n",
      "episode: 69   score: 0 global_step 3446   epsilon: 0.7084914900469609\n",
      "episode: 70   score: -4 global_step 3471   epsilon: 0.7067223851676793\n",
      "episode: 71   score: -1 global_step 3497   epsilon: 0.7048872019775732\n",
      "episode: 72   score: -2 global_step 3518   epsilon: 0.7034084181794663\n",
      "episode: 73   score: -5 global_step 3571   epsilon: 0.6996900300736497\n",
      "episode: 74   score: -8 global_step 3624   epsilon: 0.6959912982724042\n",
      "episode: 75   score: -4 global_step 3668   epsilon: 0.6929355114294197\n",
      "episode: 76   score: -3 global_step 3707   epsilon: 0.6902381912599429\n",
      "episode: 77   score: -1 global_step 3737   epsilon: 0.6881704764218188\n",
      "episode: 78   score: 0 global_step 3767   epsilon: 0.6861089557420389\n",
      "episode: 79   score: -2 global_step 3798   epsilon: 0.6839852053039812\n",
      "episode: 80   score: -4 global_step 3835   epsilon: 0.6814590100757734\n",
      "episode: 81   score: 1 global_step 3854   epsilon: 0.6801654025914671\n",
      "episode: 82   score: -2 global_step 3875   epsilon: 0.6787384826891576\n",
      "episode: 83   score: -5 global_step 3930   epsilon: 0.6750154825172562\n",
      "episode: 84   score: -2 global_step 3960   epsilon: 0.6729933696483397\n",
      "episode: 85   score: -2 global_step 3987   epsilon: 0.6711786477896918\n",
      "episode: 86   score: 0 global_step 4027   epsilon: 0.6684991617668709\n",
      "episode: 87   score: 1 global_step 4041   epsilon: 0.6675638710313676\n",
      "episode: 88   score: -2 global_step 4084   epsilon: 0.6646993662575146\n",
      "episode: 89   score: 0 global_step 4097   epsilon: 0.6638357753568291\n",
      "episode: 90   score: 1 global_step 4133   epsilon: 0.6614501439950498\n",
      "episode: 91   score: -1 global_step 4164   epsilon: 0.6594027213206963\n",
      "episode: 92   score: 0 global_step 4182   epsilon: 0.6582168047706122\n",
      "episode: 93   score: -2 global_step 4202   epsilon: 0.6569016210229519\n",
      "episode: 94   score: 1 global_step 4213   epsilon: 0.6561793904273511\n",
      "episode: 95   score: -3 global_step 4238   epsilon: 0.6545409089810712\n",
      "episode: 96   score: 0 global_step 4264   epsilon: 0.6528412281748465\n",
      "episode: 97   score: 1 global_step 4281   epsilon: 0.6517322855072429\n",
      "episode: 98   score: 1 global_step 4296   epsilon: 0.6507553711014326\n",
      "episode: 99   score: 1 global_step 4310   epsilon: 0.6498449055324687\n",
      "episode: 100   score: 1 global_step 4333   epsilon: 0.6483519052070553\n",
      "episode: 101   score: -4 global_step 4420   epsilon: 0.642735429898545\n",
      "episode: 102   score: -3 global_step 4475   epsilon: 0.6392099128149717\n",
      "episode: 103   score: -2 global_step 4502   epsilon: 0.6374862878085978\n",
      "episode: 104   score: -4 global_step 4543   epsilon: 0.63487781462699\n",
      "episode: 105   score: 1 global_step 4563   epsilon: 0.6336092645421306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 106   score: -2 global_step 4599   epsilon: 0.6313322584079054\n",
      "episode: 107   score: 1 global_step 4616   epsilon: 0.6302598517513275\n",
      "episode: 108   score: 0 global_step 4652   epsilon: 0.6279948824257438\n",
      "episode: 109   score: 0 global_step 4677   epsilon: 0.6264267777607327\n",
      "episode: 110   score: 1 global_step 4716   epsilon: 0.6239883494301238\n",
      "episode: 111   score: -12 global_step 4769   epsilon: 0.6206897951383026\n",
      "episode: 112   score: 1 global_step 4779   epsilon: 0.6200693845791024\n",
      "episode: 113   score: 0 global_step 4790   epsilon: 0.619387649191936\n",
      "episode: 114   score: -1 global_step 4831   epsilon: 0.6168532322125683\n",
      "episode: 115   score: 0 global_step 4844   epsilon: 0.6160518039798372\n",
      "episode: 116   score: -11 global_step 4897   epsilon: 0.6127952041989956\n",
      "episode: 117   score: -5 global_step 4923   epsilon: 0.6112039266601402\n",
      "episode: 118   score: 0 global_step 4955   epsilon: 0.6092511026369294\n",
      "episode: 119   score: -1 global_step 4978   epsilon: 0.6078513654277099\n",
      "episode: 120   score: 0 global_step 4998   epsilon: 0.6066368169217928\n",
      "episode: 121   score: -1 global_step 5027   epsilon: 0.6048800308829851\n",
      "episode: 122   score: 0 global_step 5036   epsilon: 0.6043358565611991\n",
      "episode: 123   score: 1 global_step 5063   epsilon: 0.6027062692007183\n",
      "episode: 124   score: -3 global_step 5084   epsilon: 0.6014418509173235\n",
      "episode: 125   score: 1 global_step 5103   epsilon: 0.6003001392835818\n",
      "episode: 126   score: -1 global_step 5130   epsilon: 0.5986814342061803\n",
      "episode: 127   score: -2 global_step 5177   epsilon: 0.5958740935147652\n",
      "episode: 128   score: 0 global_step 5196   epsilon: 0.5947429511046157\n",
      "episode: 129   score: 1 global_step 5224   epsilon: 0.5930799170227176\n",
      "episode: 130   score: 0 global_step 5237   epsilon: 0.5923093755633447\n",
      "episode: 131   score: -1 global_step 5289   epsilon: 0.5892372077587181\n",
      "episode: 132   score: 0 global_step 5300   epsilon: 0.5885893708134431\n",
      "episode: 133   score: 0 global_step 5316   epsilon: 0.5876483337978837\n",
      "episode: 134   score: 1 global_step 5337   epsilon: 0.5864155055771887\n",
      "episode: 135   score: -2 global_step 5355   epsilon: 0.5853608544045379\n",
      "episode: 136   score: 1 global_step 5387   epsilon: 0.5834906001589956\n",
      "episode: 137   score: -1 global_step 5418   epsilon: 0.5816844899088381\n",
      "episode: 138   score: -2 global_step 5444   epsilon: 0.5801739991981573\n",
      "episode: 139   score: 1 global_step 5455   epsilon: 0.5795361267990293\n",
      "episode: 140   score: 0 global_step 5464   epsilon: 0.5790147528692422\n",
      "episode: 141   score: -2 global_step 5487   epsilon: 0.5776844828200451\n",
      "episode: 142   score: -1 global_step 5503   epsilon: 0.5767608805455141\n",
      "episode: 143   score: 0 global_step 5527   epsilon: 0.5753782451254839\n",
      "episode: 144   score: 0 global_step 5580   epsilon: 0.5723366556765581\n",
      "episode: 145   score: 0 global_step 5595   epsilon: 0.571478751386197\n",
      "episode: 146   score: 1 global_step 5612   epsilon: 0.5705080143314728\n",
      "episode: 147   score: -2 global_step 5622   epsilon: 0.5699377629772988\n",
      "episode: 148   score: 1 global_step 5647   epsilon: 0.5685146270730085\n",
      "episode: 149   score: 0 global_step 5659   epsilon: 0.5678327846151296\n",
      "episode: 150   score: 1 global_step 5675   epsilon: 0.5669249332412042\n",
      "episode: 151   score: 0 global_step 5697   epsilon: 0.5656790071120201\n",
      "episode: 152   score: 0 global_step 5712   epsilon: 0.564831082307003\n",
      "episode: 153   score: 1 global_step 5734   epsilon: 0.5635897578163009\n",
      "episode: 154   score: 1 global_step 5750   epsilon: 0.5626886901959967\n",
      "episode: 155   score: 0 global_step 5758   epsilon: 0.5622386967651666\n",
      "episode: 156   score: 0 global_step 5775   epsilon: 0.561283655243105\n",
      "episode: 157   score: -2 global_step 5798   epsilon: 0.5599941218901573\n",
      "episode: 158   score: 1 global_step 5808   epsilon: 0.5594343796984346\n",
      "episode: 159   score: 1 global_step 5823   epsilon: 0.5585958152805194\n",
      "episode: 160   score: -1 global_step 5842   epsilon: 0.5575354378892678\n",
      "episode: 161   score: 1 global_step 5851   epsilon: 0.5570338566610994\n",
      "episode: 162   score: -2 global_step 5891   epsilon: 0.5548100606001298\n",
      "episode: 163   score: -1 global_step 5911   epsilon: 0.5537014939858304\n",
      "episode: 164   score: 0 global_step 5924   epsilon: 0.552982113772495\n",
      "episode: 165   score: -2 global_step 5946   epsilon: 0.5517668296596904\n",
      "episode: 166   score: 1 global_step 5963   epsilon: 0.5508295760770873\n",
      "episode: 167   score: 0 global_step 5982   epsilon: 0.5497839412675753\n",
      "episode: 168   score: 0 global_step 5996   epsilon: 0.5490147438531211\n",
      "episode: 169   score: 1 global_step 6010   epsilon: 0.5482466226153571\n",
      "episode: 170   score: -1 global_step 6060   epsilon: 0.5455120947903884\n",
      "episode: 171   score: 0 global_step 6083   epsilon: 0.5442587961523512\n",
      "episode: 172   score: 1 global_step 6098   epsilon: 0.5434429791822951\n",
      "episode: 173   score: -3 global_step 6133   epsilon: 0.5415441586868931\n",
      "episode: 174   score: 1 global_step 6153   epsilon: 0.5404620986863231\n",
      "episode: 175   score: -1 global_step 6191   epsilon: 0.5384121376045177\n",
      "episode: 176   score: -2 global_step 6214   epsilon: 0.5371751509176843\n",
      "episode: 177   score: -1 global_step 6258   epsilon: 0.5348166548235131\n",
      "episode: 178   score: 0 global_step 6278   epsilon: 0.5337480370560784\n",
      "episode: 179   score: 1 global_step 6293   epsilon: 0.5329479751931507\n",
      "episode: 180   score: -1 global_step 6316   epsilon: 0.5317235422652047\n",
      "episode: 181   score: 1 global_step 6334   epsilon: 0.5307672529924233\n",
      "episode: 182   score: 1 global_step 6349   epsilon: 0.5299716591771237\n",
      "episode: 183   score: -3 global_step 6389   epsilon: 0.5278559010880771\n",
      "episode: 184   score: 1 global_step 6422   epsilon: 0.5261167608158214\n",
      "episode: 185   score: 1 global_step 6438   epsilon: 0.5252756050440994\n",
      "episode: 186   score: 0 global_step 6458   epsilon: 0.524226051259101\n",
      "episode: 187   score: 1 global_step 6487   epsilon: 0.5227079221539402\n",
      "episode: 188   score: -1 global_step 6513   epsilon: 0.5213505789988279\n",
      "episode: 189   score: 1 global_step 6528   epsilon: 0.5205691003112941\n",
      "episode: 190   score: 1 global_step 6546   epsilon: 0.5196328719768324\n",
      "episode: 191   score: 1 global_step 6563   epsilon: 0.5187502024419509\n",
      "episode: 192   score: 0 global_step 6585   epsilon: 0.5176101495110504\n",
      "episode: 193   score: -2 global_step 6609   epsilon: 0.5163693127091433\n",
      "episode: 194   score: -1 global_step 6628   epsilon: 0.5153890935063591\n",
      "episode: 195   score: 1 global_step 6647   epsilon: 0.5144107350448348\n",
      "episode: 196   score: -1 global_step 6671   epsilon: 0.5131775680137349\n",
      "episode: 197   score: -1 global_step 6706   epsilon: 0.5113844965761547\n",
      "episode: 198   score: -1 global_step 6755   epsilon: 0.508884717013689\n",
      "episode: 199   score: 0 global_step 6788   epsilon: 0.5072080815844562\n",
      "episode: 200   score: -1 global_step 6807   epsilon: 0.5062452530639772\n",
      "episode: 201   score: -1 global_step 6823   epsilon: 0.5054358678699734\n",
      "episode: 202   score: -1 global_step 6845   epsilon: 0.5043250757395127\n",
      "episode: 203   score: -1 global_step 6940   epsilon: 0.49955643598872657\n",
      "episode: 204   score: -1 global_step 6964   epsilon: 0.4983588783075453\n",
      "episode: 205   score: 1 global_step 6984   epsilon: 0.4973631068649115\n",
      "episode: 206   score: 0 global_step 7000   epsilon: 0.496567922451223\n",
      "episode: 207   score: -3 global_step 7044   epsilon: 0.4943877145551741\n",
      "episode: 208   score: 1 global_step 7061   epsilon: 0.49354792747165616\n",
      "episode: 209   score: -1 global_step 7075   epsilon: 0.49285740932220784\n",
      "episode: 210   score: 0 global_step 7127   epsilon: 0.4903010752041619\n",
      "episode: 211   score: 1 global_step 7153   epsilon: 0.48902788461307556\n",
      "episode: 212   score: 0 global_step 7172   epsilon: 0.4880995673963149\n",
      "episode: 213   score: -2 global_step 7204   epsilon: 0.48654006733528155\n",
      "episode: 214   score: -1 global_step 7232   epsilon: 0.48517959267528793\n",
      "episode: 215   score: 1 global_step 7244   epsilon: 0.4845976972758932\n",
      "episode: 216   score: 0 global_step 7269   epsilon: 0.48338765571183356\n",
      "episode: 217   score: -1 global_step 7285   epsilon: 0.48261481525727257\n",
      "episode: 218   score: -1 global_step 7294   epsilon: 0.48218063562434105\n",
      "episode: 219   score: 0 global_step 7312   epsilon: 0.481313447823278\n",
      "episode: 220   score: 0 global_step 7326   epsilon: 0.48064004681641315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 221   score: 1 global_step 7347   epsilon: 0.4796317114232334\n",
      "episode: 222   score: 0 global_step 7367   epsilon: 0.47867335875409084\n",
      "episode: 223   score: 1 global_step 7379   epsilon: 0.4780992665427183\n",
      "episode: 224   score: -3 global_step 7418   epsilon: 0.4762382177533474\n",
      "episode: 225   score: 1 global_step 7428   epsilon: 0.4757621937856535\n",
      "episode: 226   score: 1 global_step 7440   epsilon: 0.47519159305151454\n",
      "episode: 227   score: 1 global_step 7456   epsilon: 0.474431856466523\n",
      "episode: 228   score: 0 global_step 7475   epsilon: 0.4735312467581706\n",
      "episode: 229   score: 1 global_step 7489   epsilon: 0.4728687337538259\n",
      "episode: 230   score: 1 global_step 7507   epsilon: 0.47201829313651555\n",
      "episode: 231   score: 1 global_step 7519   epsilon: 0.4714521826130046\n",
      "episode: 232   score: -1 global_step 7540   epsilon: 0.47046312245235156\n",
      "episode: 233   score: 1 global_step 7553   epsilon: 0.4698518872198804\n",
      "episode: 234   score: 0 global_step 7572   epsilon: 0.4689599716257855\n",
      "episode: 235   score: 1 global_step 7584   epsilon: 0.46839752907026794\n",
      "episode: 236   score: -2 global_step 7595   epsilon: 0.4678825493296615\n",
      "episode: 237   score: -1 global_step 7613   epsilon: 0.4670410762195196\n",
      "episode: 238   score: 0 global_step 7630   epsilon: 0.46624774124833346\n",
      "episode: 239   score: -2 global_step 7672   epsilon: 0.4642935097808335\n",
      "episode: 240   score: 0 global_step 7728   epsilon: 0.46170060339293106\n",
      "episode: 241   score: 1 global_step 7744   epsilon: 0.46096243620975813\n",
      "episode: 242   score: -2 global_step 7761   epsilon: 0.46017942666377004\n",
      "episode: 243   score: -2 global_step 7795   epsilon: 0.4586173954681161\n",
      "episode: 244   score: -3 global_step 7820   epsilon: 0.4574722267773922\n",
      "episode: 245   score: 0 global_step 7834   epsilon: 0.45683218179315604\n",
      "episode: 246   score: 1 global_step 7866   epsilon: 0.45537258243479406\n",
      "episode: 247   score: 1 global_step 7875   epsilon: 0.45496291100648695\n",
      "episode: 248   score: 0 global_step 7901   epsilon: 0.4537814848851073\n",
      "episode: 249   score: 0 global_step 7917   epsilon: 0.45305597879303794\n",
      "episode: 250   score: 1 global_step 7946   epsilon: 0.45174395420742114\n",
      "episode: 251   score: 1 global_step 7977   epsilon: 0.45034564652959697\n",
      "episode: 252   score: 1 global_step 7992   epsilon: 0.4496706007178857\n",
      "episode: 253   score: 1 global_step 8003   epsilon: 0.4491762103017457\n",
      "episode: 254   score: 0 global_step 8023   epsilon: 0.4482787108040984\n",
      "episode: 255   score: 1 global_step 8039   epsilon: 0.4475620025503103\n",
      "episode: 256   score: 0 global_step 8078   epsilon: 0.4458198230882127\n",
      "episode: 257   score: -3 global_step 8100   epsilon: 0.44484004863497356\n",
      "episode: 258   score: -3 global_step 8181   epsilon: 0.4412512191787496\n",
      "episode: 259   score: 0 global_step 8199   epsilon: 0.4404576417386672\n",
      "episode: 260   score: -2 global_step 8221   epsilon: 0.4394896517060119\n",
      "episode: 261   score: 0 global_step 8238   epsilon: 0.4387431167052897\n",
      "episode: 262   score: 1 global_step 8251   epsilon: 0.4381730927477547\n",
      "episode: 263   score: 1 global_step 8266   epsilon: 0.4375162929910716\n",
      "episode: 264   score: -1 global_step 8330   epsilon: 0.4347249908434825\n",
      "episode: 265   score: 1 global_step 8347   epsilon: 0.4339865492895267\n",
      "episode: 266   score: -1 global_step 8391   epsilon: 0.43208110824357826\n",
      "episode: 267   score: -1 global_step 8434   epsilon: 0.4302270558435537\n",
      "episode: 268   score: -1 global_step 8453   epsilon: 0.42941035970899316\n",
      "episode: 269   score: 1 global_step 8466   epsilon: 0.4288524610586715\n",
      "episode: 270   score: 1 global_step 8485   epsilon: 0.4280383743049767\n",
      "episode: 271   score: 0 global_step 8506   epsilon: 0.4271403920304876\n",
      "episode: 272   score: 0 global_step 8520   epsilon: 0.42654278402396534\n",
      "episode: 273   score: 0 global_step 8533   epsilon: 0.42598861098614504\n",
      "episode: 274   score: 1 global_step 8550   epsilon: 0.4252650094024088\n",
      "episode: 275   score: 1 global_step 8562   epsilon: 0.42475497197249495\n",
      "episode: 276   score: 1 global_step 8573   epsilon: 0.42428797504848925\n",
      "episode: 277   score: 0 global_step 8588   epsilon: 0.4236519883952973\n",
      "episode: 278   score: 1 global_step 8604   epsilon: 0.42297465335908296\n",
      "episode: 279   score: 1 global_step 8621   epsilon: 0.42225617140637917\n",
      "episode: 280   score: -1 global_step 8642   epsilon: 0.4213703196230378\n",
      "episode: 281   score: 1 global_step 8662   epsilon: 0.4205283791072411\n",
      "episode: 282   score: 0 global_step 8696   epsilon: 0.41910093926799097\n",
      "episode: 283   score: 0 global_step 8718   epsilon: 0.41817988467966216\n",
      "episode: 284   score: 1 global_step 8736   epsilon: 0.4174278003613555\n",
      "episode: 285   score: 0 global_step 8761   epsilon: 0.41638548218429716\n",
      "episode: 286   score: 1 global_step 8777   epsilon: 0.4157197648422809\n",
      "episode: 287   score: 1 global_step 8792   epsilon: 0.41509662151167487\n",
      "episode: 288   score: 0 global_step 8808   epsilon: 0.4144329648008234\n",
      "episode: 289   score: 0 global_step 8849   epsilon: 0.4127371835817899\n",
      "episode: 290   score: 1 global_step 8873   epsilon: 0.4117477526608789\n",
      "episode: 291   score: 1 global_step 8890   epsilon: 0.41104834117840844\n",
      "episode: 292   score: 1 global_step 8904   epsilon: 0.4104732474051687\n",
      "episode: 293   score: 0 global_step 8931   epsilon: 0.40936640919835904\n",
      "episode: 294   score: 1 global_step 8952   epsilon: 0.40850759886428956\n",
      "episode: 295   score: 0 global_step 8973   epsilon: 0.4076505902295616\n",
      "episode: 296   score: 1 global_step 8991   epsilon: 0.40691744254003337\n",
      "episode: 297   score: 1 global_step 9003   epsilon: 0.40642941008499583\n",
      "episode: 298   score: -4 global_step 9039   epsilon: 0.4049688218144598\n",
      "episode: 299   score: 1 global_step 9054   epsilon: 0.4043617936147956\n",
      "episode: 300   score: -1 global_step 9074   epsilon: 0.4035538378541973\n",
      "episode: 301   score: 0 global_step 9088   epsilon: 0.4029892295683407\n",
      "episode: 302   score: 1 global_step 9099   epsilon: 0.402546162993412\n",
      "episode: 303   score: -1 global_step 9110   epsilon: 0.40210358354810205\n",
      "episode: 304   score: 1 global_step 9127   epsilon: 0.4014205540436092\n",
      "episode: 305   score: 0 global_step 9145   epsilon: 0.40069861089234204\n",
      "episode: 306   score: 1 global_step 9156   epsilon: 0.4002580627384945\n",
      "episode: 307   score: -1 global_step 9173   epsilon: 0.3995781681107242\n",
      "episode: 308   score: 0 global_step 9194   epsilon: 0.398739892540645\n",
      "episode: 309   score: 1 global_step 9215   epsilon: 0.39790337558999866\n",
      "episode: 310   score: 0 global_step 9225   epsilon: 0.39750565122318765\n",
      "episode: 311   score: -1 global_step 9250   epsilon: 0.3965130786983231\n",
      "episode: 312   score: 1 global_step 9267   epsilon: 0.39583954545278854\n",
      "episode: 313   score: -1 global_step 9287   epsilon: 0.39504861800595403\n",
      "episode: 314   score: 1 global_step 9297   epsilon: 0.3946537471124286\n",
      "episode: 315   score: 1 global_step 9308   epsilon: 0.3942198449850611\n",
      "episode: 316   score: 0 global_step 9323   epsilon: 0.3936289289691044\n",
      "episode: 317   score: -3 global_step 9369   epsilon: 0.3918223039863927\n",
      "episode: 318   score: -1 global_step 9435   epsilon: 0.389244663466919\n",
      "episode: 319   score: -1 global_step 9450   epsilon: 0.38866120500156215\n",
      "episode: 320   score: 1 global_step 9477   epsilon: 0.3876131828127353\n",
      "episode: 321   score: 1 global_step 9495   epsilon: 0.3869160718156684\n",
      "episode: 322   score: 1 global_step 9512   epsilon: 0.38625884043642866\n",
      "episode: 323   score: 1 global_step 9528   epsilon: 0.3856412895861042\n",
      "episode: 324   score: -2 global_step 9552   epsilon: 0.3847168140809286\n",
      "episode: 325   score: 1 global_step 9567   epsilon: 0.38414014263746826\n",
      "episode: 326   score: 0 global_step 9588   epsilon: 0.3833342545215526\n",
      "episode: 327   score: 0 global_step 9604   epsilon: 0.38272137950082613\n",
      "episode: 328   score: 1 global_step 9622   epsilon: 0.3820330662692518\n",
      "episode: 329   score: -2 global_step 9643   epsilon: 0.38123159859165034\n",
      "episode: 330   score: 1 global_step 9665   epsilon: 0.3803937691329237\n",
      "episode: 331   score: 1 global_step 9695   epsilon: 0.379254240995064\n",
      "episode: 332   score: 0 global_step 9711   epsilon: 0.3786478891022477\n",
      "episode: 333   score: 1 global_step 9729   epsilon: 0.37796690192427324\n",
      "episode: 334   score: 1 global_step 9746   epsilon: 0.37732487196906095\n",
      "episode: 335   score: 1 global_step 9760   epsilon: 0.3767969603766293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 336   score: 1 global_step 9771   epsilon: 0.3763826908963842\n",
      "episode: 337   score: 1 global_step 9782   epsilon: 0.3759688768847875\n",
      "episode: 338   score: 0 global_step 9795   epsilon: 0.37548041049306113\n",
      "episode: 339   score: -2 global_step 9809   epsilon: 0.3749550794689071\n",
      "episode: 340   score: -2 global_step 9859   epsilon: 0.3730848899307937\n",
      "episode: 341   score: 0 global_step 9867   epsilon: 0.37278652646172816\n",
      "episode: 342   score: 0 global_step 9881   epsilon: 0.37226496442476387\n",
      "episode: 343   score: 1 global_step 9899   epsilon: 0.3715954567505406\n",
      "episode: 344   score: 1 global_step 9918   epsilon: 0.37089006045101364\n",
      "episode: 345   score: 1 global_step 9930   epsilon: 0.3704452370843349\n",
      "episode: 346   score: 1 global_step 9946   epsilon: 0.3698529690319025\n",
      "episode: 347   score: 1 global_step 9957   epsilon: 0.36944633412408684\n",
      "episode: 348   score: 1 global_step 9973   epsilon: 0.3688556631182666\n",
      "episode: 349   score: 1 global_step 9999   epsilon: 0.36789783621659083\n",
      "episode: 350   score: 1 global_step 10020   epsilon: 0.3671260228569082\n",
      "episode: 351   score: 0 global_step 10039   epsilon: 0.3664291108433765\n",
      "episode: 352   score: -1 global_step 10068   epsilon: 0.3653679527860587\n",
      "episode: 353   score: 1 global_step 10082   epsilon: 0.364856770004038\n",
      "episode: 354   score: 1 global_step 10100   epsilon: 0.36420058575127745\n",
      "episode: 355   score: 1 global_step 10115   epsilon: 0.36365466711760414\n",
      "episode: 356   score: -2 global_step 10135   epsilon: 0.36292804831284636\n",
      "episode: 357   score: 0 global_step 10182   epsilon: 0.3612262038595677\n",
      "episode: 358   score: 1 global_step 10207   epsilon: 0.3603242211981669\n",
      "episode: 359   score: 1 global_step 10218   epsilon: 0.3599280626737291\n",
      "episode: 360   score: 1 global_step 10233   epsilon: 0.35938854834046624\n",
      "episode: 361   score: 1 global_step 10248   epsilon: 0.35884984271245857\n",
      "episode: 362   score: 1 global_step 10271   epsilon: 0.35802539532911654\n",
      "episode: 363   score: 1 global_step 10293   epsilon: 0.3572385659469585\n",
      "episode: 364   score: 1 global_step 10302   epsilon: 0.35691717981348653\n",
      "episode: 365   score: 0 global_step 10328   epsilon: 0.35599035419935476\n",
      "episode: 366   score: 1 global_step 10344   epsilon: 0.35542119662177096\n",
      "episode: 367   score: 1 global_step 10353   epsilon: 0.35510144546659134\n",
      "episode: 368   score: 1 global_step 10375   epsilon: 0.3543210420243075\n",
      "episode: 369   score: 0 global_step 10387   epsilon: 0.35389609054783305\n",
      "episode: 370   score: 0 global_step 10437   epsilon: 0.3521309383939825\n",
      "episode: 371   score: -2 global_step 10472   epsilon: 0.35090057298583266\n",
      "episode: 372   score: 0 global_step 10480   epsilon: 0.35061995075995644\n",
      "episode: 373   score: 0 global_step 10504   epsilon: 0.34977942987991445\n",
      "episode: 374   score: 0 global_step 10527   epsilon: 0.3489758215139986\n",
      "episode: 375   score: 1 global_step 10537   epsilon: 0.34862700268973457\n",
      "episode: 376   score: 1 global_step 10550   epsilon: 0.3481740594156177\n",
      "episode: 377   score: 1 global_step 10560   epsilon: 0.3478260419927552\n",
      "episode: 378   score: 0 global_step 10585   epsilon: 0.3469575195663394\n",
      "episode: 379   score: 1 global_step 10601   epsilon: 0.34640280368982374\n",
      "episode: 380   score: 1 global_step 10619   epsilon: 0.3457798083569129\n",
      "episode: 381   score: 0 global_step 10640   epsilon: 0.34505439643728075\n",
      "episode: 382   score: 1 global_step 10662   epsilon: 0.3442960733096432\n",
      "episode: 383   score: 1 global_step 10679   epsilon: 0.3437112379936371\n",
      "episode: 384   score: 1 global_step 10693   epsilon: 0.3432303549125962\n",
      "episode: 385   score: 1 global_step 10707   epsilon: 0.34275014463044007\n",
      "episode: 386   score: 1 global_step 10726   epsilon: 0.3420995051263976\n",
      "episode: 387   score: 1 global_step 10737   epsilon: 0.3417233837690512\n",
      "episode: 388   score: 0 global_step 10758   epsilon: 0.3410064818279546\n",
      "episode: 389   score: 1 global_step 10768   epsilon: 0.34066562875812995\n",
      "episode: 390   score: -1 global_step 10786   epsilon: 0.3400529515668986\n",
      "episode: 391   score: 1 global_step 10804   epsilon: 0.3394413762577149\n",
      "episode: 392   score: 1 global_step 10820   epsilon: 0.3388986771953288\n",
      "episode: 393   score: 1 global_step 10831   epsilon: 0.33852607498877935\n",
      "episode: 394   score: 1 global_step 10848   epsilon: 0.3379510408266432\n",
      "episode: 395   score: 0 global_step 10862   epsilon: 0.33747821678195283\n",
      "episode: 396   score: 1 global_step 10873   epsilon: 0.3371071763008392\n",
      "episode: 397   score: 1 global_step 10883   epsilon: 0.3367702207823219\n",
      "episode: 398   score: 1 global_step 10895   epsilon: 0.33636631871165606\n",
      "episode: 399   score: 0 global_step 10912   epsilon: 0.3357949531993906\n",
      "episode: 400   score: 1 global_step 10925   epsilon: 0.33535868158428156\n",
      "episode: 401   score: 0 global_step 10943   epsilon: 0.33475554878266267\n",
      "episode: 402   score: 1 global_step 10960   epsilon: 0.33418691938972445\n",
      "episode: 403   score: 0 global_step 10978   epsilon: 0.33358589396821536\n",
      "episode: 404   score: 1 global_step 10996   epsilon: 0.3329859494733864\n",
      "episode: 405   score: 1 global_step 11029   epsilon: 0.3318888521905281\n",
      "episode: 406   score: 1 global_step 11052   epsilon: 0.3311263469218047\n",
      "episode: 407   score: 0 global_step 11091   epsilon: 0.3298374047915983\n",
      "episode: 408   score: 1 global_step 11108   epsilon: 0.3292771295581123\n",
      "episode: 409   score: 1 global_step 11125   epsilon: 0.32871780603092965\n",
      "episode: 410   score: 1 global_step 11140   epsilon: 0.32822507432605785\n",
      "episode: 411   score: 1 global_step 11153   epsilon: 0.3277986376511431\n",
      "episode: 412   score: 1 global_step 11166   epsilon: 0.32737275501140706\n",
      "episode: 413   score: 1 global_step 11177   epsilon: 0.3270128249819041\n",
      "episode: 414   score: 1 global_step 11199   epsilon: 0.32629415166320913\n",
      "episode: 415   score: 1 global_step 11213   epsilon: 0.3258376366598203\n",
      "episode: 416   score: 0 global_step 11236   epsilon: 0.3250890338879535\n",
      "episode: 417   score: 1 global_step 11253   epsilon: 0.3245368244304469\n",
      "episode: 418   score: 0 global_step 11261   epsilon: 0.32427728582304166\n",
      "episode: 419   score: 1 global_step 11276   epsilon: 0.32379121023795543\n",
      "episode: 420   score: 1 global_step 11290   epsilon: 0.3233381970757961\n",
      "episode: 421   score: 1 global_step 11306   epsilon: 0.3228212437853007\n",
      "episode: 422   score: 1 global_step 11320   epsilon: 0.32236958769385865\n",
      "episode: 423   score: 1 global_step 11343   epsilon: 0.32162895266658853\n",
      "episode: 424   score: -1 global_step 11379   epsilon: 0.3204731124048531\n",
      "episode: 425   score: 0 global_step 11400   epsilon: 0.3198007914363015\n",
      "episode: 426   score: 1 global_step 11419   epsilon: 0.3191937164821629\n",
      "episode: 427   score: 1 global_step 11440   epsilon: 0.31852407956001827\n",
      "episode: 428   score: 0 global_step 11457   epsilon: 0.3179830216009939\n",
      "episode: 429   score: 0 global_step 11498   epsilon: 0.31668189528672597\n",
      "episode: 430   score: 0 global_step 11520   epsilon: 0.31598592616481486\n",
      "episode: 431   score: 1 global_step 11535   epsilon: 0.3155122789170597\n",
      "episode: 432   score: 1 global_step 11551   epsilon: 0.3150078377088976\n",
      "episode: 433   score: 1 global_step 11563   epsilon: 0.31463003613953366\n",
      "episode: 434   score: 1 global_step 11577   epsilon: 0.31418984028777747\n",
      "episode: 435   score: 1 global_step 11591   epsilon: 0.3137502603097956\n",
      "episode: 436   score: 1 global_step 11605   epsilon: 0.3133112953439251\n",
      "episode: 437   score: 1 global_step 11618   epsilon: 0.31290423495320374\n",
      "episode: 438   score: -2 global_step 11636   epsilon: 0.31234148581853344\n",
      "episode: 439   score: 0 global_step 11721   epsilon: 0.3096977029932913\n",
      "episode: 440   score: 0 global_step 11742   epsilon: 0.3090479877704692\n",
      "episode: 441   score: 1 global_step 11758   epsilon: 0.30855388167461123\n",
      "episode: 442   score: 1 global_step 11780   epsilon: 0.30787577541944644\n",
      "episode: 443   score: 0 global_step 11797   epsilon: 0.3073528051030057\n",
      "episode: 444   score: 1 global_step 11820   epsilon: 0.306646670709816\n",
      "episode: 445   score: 0 global_step 11833   epsilon: 0.3062482691346174\n",
      "episode: 446   score: 0 global_step 11848   epsilon: 0.3057892181522969\n",
      "episode: 447   score: -4 global_step 11904   epsilon: 0.3040814992193462\n",
      "episode: 448   score: -2 global_step 11940   epsilon: 0.30298871936625\n",
      "episode: 449   score: 1 global_step 11954   epsilon: 0.3025648107686144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 450   score: 0 global_step 11974   epsilon: 0.30196025567544027\n",
      "episode: 451   score: 1 global_step 12003   epsilon: 0.30108579578997374\n",
      "episode: 452   score: 1 global_step 12020   epsilon: 0.30057435920914644\n",
      "episode: 453   score: 0 global_step 12031   epsilon: 0.30024389268032914\n",
      "episode: 454   score: 1 global_step 12041   epsilon: 0.2999437838613776\n",
      "episode: 455   score: 1 global_step 12052   epsilon: 0.2996140106187304\n",
      "episode: 456   score: 1 global_step 12065   epsilon: 0.2992247460181861\n",
      "episode: 457   score: 1 global_step 12076   epsilon: 0.2988957633218143\n",
      "episode: 458   score: 1 global_step 12084   epsilon: 0.29865673038523455\n",
      "episode: 459   score: 0 global_step 12094   epsilon: 0.2983582080145455\n",
      "episode: 460   score: 1 global_step 12104   epsilon: 0.29805998403192785\n",
      "episode: 461   score: 1 global_step 12118   epsilon: 0.2976429711804046\n",
      "episode: 462   score: 1 global_step 12135   epsilon: 0.29713738272151247\n",
      "episode: 463   score: 1 global_step 12155   epsilon: 0.29654367217850397\n",
      "episode: 464   score: -1 global_step 12179   epsilon: 0.2958327852259213\n",
      "episode: 465   score: 1 global_step 12198   epsilon: 0.2952712085215075\n",
      "episode: 466   score: 1 global_step 12219   epsilon: 0.29465175866061627\n",
      "episode: 467   score: 1 global_step 12237   epsilon: 0.29412183607187237\n",
      "episode: 468   score: 0 global_step 12255   epsilon: 0.2935928665334387\n",
      "episode: 469   score: 1 global_step 12283   epsilon: 0.29277191532697117\n",
      "episode: 470   score: 1 global_step 12299   epsilon: 0.29230383142484745\n",
      "episode: 471   score: 1 global_step 12313   epsilon: 0.29189487195096997\n",
      "episode: 472   score: 0 global_step 12329   epsilon: 0.29142819026628686\n",
      "episode: 473   score: 1 global_step 12347   epsilon: 0.29090406517122247\n",
      "episode: 474   score: 1 global_step 12382   epsilon: 0.28988762991986616\n",
      "episode: 475   score: 1 global_step 12402   epsilon: 0.28930840511619177\n",
      "episode: 476   score: 1 global_step 12434   epsilon: 0.28838405175557963\n",
      "episode: 477   score: 1 global_step 12449   epsilon: 0.2879517783500252\n",
      "episode: 478   score: 0 global_step 12464   epsilon: 0.2875201529008887\n",
      "episode: 479   score: 0 global_step 12489   epsilon: 0.28680221441816256\n",
      "episode: 480   score: 0 global_step 12526   epsilon: 0.28574295410100314\n",
      "episode: 481   score: 1 global_step 12563   epsilon: 0.284687606000567\n",
      "episode: 482   score: 1 global_step 12584   epsilon: 0.2840903594934742\n",
      "episode: 483   score: 1 global_step 12599   epsilon: 0.28366452211988924\n",
      "episode: 484   score: 0 global_step 12615   epsilon: 0.2832109991231235\n",
      "episode: 485   score: 0 global_step 12637   epsilon: 0.2825885887065228\n",
      "episode: 486   score: 0 global_step 12656   epsilon: 0.2820521533407481\n",
      "episode: 487   score: 0 global_step 12703   epsilon: 0.2807295526353752\n",
      "episode: 488   score: 1 global_step 12731   epsilon: 0.2799445701266096\n",
      "episode: 489   score: 1 global_step 12745   epsilon: 0.27955290237611935\n",
      "episode: 490   score: 0 global_step 12775   epsilon: 0.27871545858989727\n",
      "episode: 491   score: 1 global_step 12786   epsilon: 0.27840902483297175\n",
      "episode: 492   score: 1 global_step 12795   epsilon: 0.2781585569144882\n",
      "episode: 493   score: 1 global_step 12806   epsilon: 0.2778527354432017\n",
      "episode: 494   score: 1 global_step 12819   epsilon: 0.27749174353281314\n",
      "episode: 495   score: -1 global_step 12839   epsilon: 0.2769372869638539\n",
      "episode: 496   score: 0 global_step 12855   epsilon: 0.2764945194744216\n",
      "episode: 497   score: 1 global_step 12873   epsilon: 0.2759972521504475\n",
      "episode: 498   score: 1 global_step 12884   epsilon: 0.27569380692604023\n",
      "episode: 499   score: 1 global_step 12898   epsilon: 0.2753080863773831\n",
      "episode: 500   score: 1 global_step 12911   epsilon: 0.2749504005266815\n",
      "episode: 501   score: 0 global_step 12934   epsilon: 0.27431870974328976\n",
      "episode: 502   score: 1 global_step 12960   epsilon: 0.2736063719209454\n",
      "episode: 503   score: 1 global_step 12975   epsilon: 0.273196249525301\n",
      "episode: 504   score: 1 global_step 12988   epsilon: 0.2728413074158782\n",
      "episode: 505   score: 1 global_step 13029   epsilon: 0.27172489244846676\n",
      "episode: 506   score: 0 global_step 13049   epsilon: 0.27118195863123074\n",
      "episode: 507   score: 1 global_step 13068   epsilon: 0.2706671763683105\n",
      "episode: 508   score: 1 global_step 13080   epsilon: 0.27034255433747156\n",
      "episode: 509   score: 1 global_step 13097   epsilon: 0.26988333947720317\n",
      "episode: 510   score: 1 global_step 13111   epsilon: 0.26950574829756346\n",
      "episode: 511   score: 1 global_step 13123   epsilon: 0.26918251921412234\n",
      "episode: 512   score: 0 global_step 13148   epsilon: 0.2685103698448653\n",
      "episode: 513   score: 1 global_step 13162   epsilon: 0.26813469957380826\n",
      "episode: 514   score: 1 global_step 13174   epsilon: 0.26781311484424497\n",
      "episode: 515   score: 1 global_step 13191   epsilon: 0.26735819659279675\n",
      "episode: 516   score: 1 global_step 13207   epsilon: 0.2669307441584123\n",
      "episode: 517   score: 0 global_step 13225   epsilon: 0.2664506770052319\n",
      "episode: 518   score: 1 global_step 13242   epsilon: 0.2659980730461206\n",
      "episode: 519   score: 1 global_step 13260   epsilon: 0.26551968327471626\n",
      "episode: 520   score: 1 global_step 13272   epsilon: 0.2652012348393764\n",
      "episode: 521   score: 1 global_step 13298   epsilon: 0.26451257284368057\n",
      "episode: 522   score: 1 global_step 13308   epsilon: 0.26424817926975874\n",
      "episode: 523   score: 0 global_step 13322   epsilon: 0.26387847218846444\n",
      "episode: 524   score: 1 global_step 13340   epsilon: 0.2634038944573436\n",
      "episode: 525   score: 1 global_step 13362   epsilon: 0.26282501394708435\n",
      "episode: 526   score: 1 global_step 13376   epsilon: 0.2624572980026792\n",
      "episode: 527   score: 1 global_step 13391   epsilon: 0.2620638875164559\n",
      "episode: 528   score: 1 global_step 13406   epsilon: 0.2616710667330598\n",
      "episode: 529   score: 0 global_step 13422   epsilon: 0.2612527068850789\n",
      "episode: 530   score: 1 global_step 13440   epsilon: 0.26078285151622493\n",
      "episode: 531   score: -1 global_step 13474   epsilon: 0.25989765125355085\n",
      "episode: 532   score: 1 global_step 13489   epsilon: 0.25950807755098654\n",
      "episode: 533   score: 1 global_step 13504   epsilon: 0.2591190878001007\n",
      "episode: 534   score: 1 global_step 13517   epsilon: 0.2587824350247596\n",
      "episode: 535   score: 0 global_step 13566   epsilon: 0.2575174396122449\n",
      "episode: 536   score: 0 global_step 13599   epsilon: 0.25666899034964363\n",
      "episode: 537   score: -2 global_step 13650   epsilon: 0.255363245689764\n",
      "episode: 538   score: -1 global_step 13676   epsilon: 0.25470013051795637\n",
      "episode: 539   score: 0 global_step 13696   epsilon: 0.2541912138969337\n",
      "episode: 540   score: -2 global_step 13762   epsilon: 0.2525189926732595\n",
      "episode: 541   score: 0 global_step 13771   epsilon: 0.2522918164654825\n",
      "episode: 542   score: 0 global_step 13793   epsilon: 0.2517373568750095\n",
      "episode: 543   score: 1 global_step 13820   epsilon: 0.2510585488736796\n",
      "episode: 544   score: 0 global_step 13855   epsilon: 0.2501813361091231\n",
      "episode: 545   score: 0 global_step 13879   epsilon: 0.24958159089684762\n",
      "episode: 546   score: 1 global_step 13898   epsilon: 0.24910781241691624\n",
      "episode: 547   score: 1 global_step 13908   epsilon: 0.2488588166731272\n",
      "episode: 548   score: -2 global_step 13977   epsilon: 0.24714751604869903\n",
      "episode: 549   score: 0 global_step 13996   epsilon: 0.2466783581510688\n",
      "episode: 550   score: 1 global_step 14014   epsilon: 0.2462347143230708\n",
      "episode: 551   score: 0 global_step 14033   epsilon: 0.24576728918871255\n",
      "episode: 552   score: 1 global_step 14052   epsilon: 0.24530075136326532\n",
      "episode: 553   score: 1 global_step 14070   epsilon: 0.2448595851208707\n",
      "episode: 554   score: 1 global_step 14084   epsilon: 0.24451700443481958\n",
      "episode: 555   score: 1 global_step 14093   epsilon: 0.24429702713641352\n",
      "episode: 556   score: 1 global_step 14104   epsilon: 0.24402843472962749\n",
      "episode: 557   score: 1 global_step 14113   epsilon: 0.24380889696811203\n",
      "episode: 558   score: 0 global_step 14122   epsilon: 0.2435895567115668\n",
      "episode: 559   score: 1 global_step 14133   epsilon: 0.24332174213325605\n",
      "episode: 560   score: 1 global_step 14151   epsilon: 0.24288413508120563\n",
      "episode: 561   score: 1 global_step 14163   epsilon: 0.2425928343692149\n",
      "episode: 562   score: 1 global_step 14174   epsilon: 0.24232611563744794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 563   score: 1 global_step 14184   epsilon: 0.2420838985394885\n",
      "episode: 564   score: 1 global_step 14194   epsilon: 0.2418419235496584\n",
      "episode: 565   score: 1 global_step 14204   epsilon: 0.24160019042595837\n",
      "episode: 566   score: 1 global_step 14214   epsilon: 0.24135869892663117\n",
      "episode: 567   score: 1 global_step 14226   epsilon: 0.2410692277315736\n",
      "episode: 568   score: -1 global_step 14270   epsilon: 0.2400108004549982\n",
      "episode: 569   score: 1 global_step 14283   epsilon: 0.23969897355420516\n",
      "episode: 570   score: 1 global_step 14295   epsilon: 0.23941149293454075\n",
      "episode: 571   score: 1 global_step 14308   epsilon: 0.23910044466623578\n",
      "episode: 572   score: 1 global_step 14321   epsilon: 0.23878980051815096\n",
      "episode: 573   score: 1 global_step 14336   epsilon: 0.23843186643804756\n",
      "episode: 574   score: 1 global_step 14348   epsilon: 0.23814590551091055\n",
      "episode: 575   score: 0 global_step 14367   epsilon: 0.23769383528926716\n",
      "episode: 576   score: 0 global_step 14382   epsilon: 0.2373375440067421\n",
      "episode: 577   score: 1 global_step 14398   epsilon: 0.23695808860851825\n",
      "episode: 578   score: 0 global_step 14428   epsilon: 0.2362482441489774\n",
      "episode: 579   score: 0 global_step 14460   epsilon: 0.2354934203880495\n",
      "episode: 580   score: 0 global_step 14474   epsilon: 0.23516394381282274\n",
      "episode: 581   score: 1 global_step 14486   epsilon: 0.23488190223672586\n",
      "episode: 582   score: 1 global_step 14504   epsilon: 0.23445947399041847\n",
      "episode: 583   score: 1 global_step 14526   epsilon: 0.23394420438812843\n",
      "episode: 584   score: 1 global_step 14548   epsilon: 0.23343006718948384\n",
      "episode: 585   score: 1 global_step 14571   epsilon: 0.23289376819982\n",
      "episode: 586   score: 1 global_step 14587   epsilon: 0.23252141751284403\n",
      "episode: 587   score: 1 global_step 14599   epsilon: 0.232242545224821\n",
      "episode: 588   score: 1 global_step 14609   epsilon: 0.23201040716087737\n",
      "episode: 589   score: 1 global_step 14619   epsilon: 0.23177850113056336\n",
      "episode: 590   score: 0 global_step 14634   epsilon: 0.23143107664086623\n",
      "episode: 591   score: 1 global_step 14648   epsilon: 0.23110728365163105\n",
      "episode: 592   score: 1 global_step 14658   epsilon: 0.23087628033852906\n",
      "episode: 593   score: 1 global_step 14671   epsilon: 0.23057632119157354\n",
      "episode: 594   score: 1 global_step 14687   epsilon: 0.2302076756401717\n",
      "episode: 595   score: 1 global_step 14702   epsilon: 0.2298626057400578\n",
      "episode: 596   score: 1 global_step 14717   epsilon: 0.22951805308262768\n",
      "episode: 597   score: 0 global_step 14748   epsilon: 0.2288076133460566\n",
      "episode: 598   score: 0 global_step 14811   epsilon: 0.22737058492209936\n",
      "episode: 599   score: 0 global_step 14842   epsilon: 0.22666679236074505\n",
      "episode: 600   score: 0 global_step 14886   epsilon: 0.22567159974331316\n",
      "episode: 601   score: 1 global_step 14916   epsilon: 0.22499556569993362\n",
      "episode: 602   score: -1 global_step 14944   epsilon: 0.2243664278625872\n",
      "episode: 603   score: 0 global_step 14958   epsilon: 0.22405251895538206\n",
      "episode: 604   score: 1 global_step 15003   epsilon: 0.22304649756405093\n",
      "episode: 605   score: 1 global_step 15016   epsilon: 0.22275671102971042\n",
      "episode: 606   score: 0 global_step 15031   epsilon: 0.2224228097563886\n",
      "episode: 607   score: 0 global_step 15041   epsilon: 0.22220048701021058\n",
      "episode: 608   score: 1 global_step 15053   epsilon: 0.22193399302924677\n",
      "episode: 609   score: 1 global_step 15063   epsilon: 0.221712158879887\n",
      "episode: 610   score: 1 global_step 15078   epsilon: 0.22137982333848524\n",
      "episode: 611   score: 1 global_step 15091   epsilon: 0.22109220218110864\n",
      "episode: 612   score: 1 global_step 15114   epsilon: 0.22058424908800506\n",
      "episode: 613   score: 1 global_step 15134   epsilon: 0.22014349944854317\n",
      "episode: 614   score: 1 global_step 15146   epsilon: 0.2198794724954939\n",
      "episode: 615   score: 1 global_step 15160   epsilon: 0.2195718412443061\n",
      "episode: 616   score: 1 global_step 15169   epsilon: 0.21937430561460783\n",
      "episode: 617   score: 1 global_step 15182   epsilon: 0.21908929006654193\n",
      "episode: 618   score: 1 global_step 15191   epsilon: 0.2188921885592257\n",
      "episode: 619   score: 1 global_step 15201   epsilon: 0.2186733948458889\n",
      "episode: 620   score: 1 global_step 15214   epsilon: 0.21838928993531234\n",
      "episode: 621   score: 1 global_step 15228   epsilon: 0.21808374358418495\n",
      "episode: 622   score: 0 global_step 15243   epsilon: 0.2177568468575411\n",
      "episode: 623   score: 1 global_step 15258   epsilon: 0.21743044013289436\n",
      "episode: 624   score: 1 global_step 15270   epsilon: 0.2171696670610015\n",
      "episode: 625   score: 1 global_step 15283   epsilon: 0.21688751582406748\n",
      "episode: 626   score: 1 global_step 15318   epsilon: 0.21612969858100867\n",
      "episode: 627   score: 1 global_step 15327   epsilon: 0.21593525964082508\n",
      "episode: 628   score: 0 global_step 15335   epsilon: 0.21576257188289427\n",
      "episode: 629   score: 1 global_step 15353   epsilon: 0.21537452919424382\n",
      "episode: 630   score: 1 global_step 15364   epsilon: 0.21513773563259156\n",
      "episode: 631   score: 1 global_step 15376   epsilon: 0.21487971229341832\n",
      "episode: 632   score: 1 global_step 15388   epsilon: 0.21462199841201346\n",
      "episode: 633   score: 1 global_step 15400   epsilon: 0.21436459361723184\n",
      "episode: 634   score: 1 global_step 15417   epsilon: 0.21400046519821303\n",
      "episode: 635   score: 0 global_step 15432   epsilon: 0.21367968910356316\n",
      "episode: 636   score: 1 global_step 15446   epsilon: 0.2133807319095773\n",
      "episode: 637   score: 1 global_step 15455   epsilon: 0.2131887660500009\n",
      "episode: 638   score: 1 global_step 15467   epsilon: 0.21293308018843551\n",
      "episode: 639   score: 1 global_step 15487   epsilon: 0.21250761835827053\n",
      "episode: 640   score: 1 global_step 15499   epsilon: 0.21225274942452763\n",
      "episode: 641   score: 1 global_step 15517   epsilon: 0.21187101904913686\n",
      "episode: 642   score: 1 global_step 15532   epsilon: 0.2115534348887608\n",
      "episode: 643   score: 1 global_step 15544   epsilon: 0.21129971034563008\n",
      "episode: 644   score: 1 global_step 15555   epsilon: 0.21106739684423315\n",
      "episode: 645   score: 1 global_step 15565   epsilon: 0.21085642440239383\n",
      "episode: 646   score: 1 global_step 15577   epsilon: 0.21060353581197314\n",
      "episode: 647   score: 1 global_step 15589   epsilon: 0.21035095052101008\n",
      "episode: 648   score: 0 global_step 15601   epsilon: 0.2100986681657454\n",
      "episode: 649   score: 1 global_step 15615   epsilon: 0.2098047211436465\n",
      "episode: 650   score: 1 global_step 15629   epsilon: 0.2095111853799938\n",
      "episode: 651   score: 0 global_step 15644   epsilon: 0.20919713849336946\n",
      "episode: 652   score: 0 global_step 15656   epsilon: 0.20894623995127581\n",
      "episode: 653   score: 1 global_step 15664   epsilon: 0.20877914145256246\n",
      "episode: 654   score: 1 global_step 15676   epsilon: 0.20852874423113166\n",
      "episode: 655   score: 1 global_step 15695   epsilon: 0.2081328959992616\n",
      "episode: 656   score: 1 global_step 15709   epsilon: 0.2078416992700585\n",
      "episode: 657   score: 0 global_step 15734   epsilon: 0.2073227180692081\n",
      "episode: 658   score: 1 global_step 15749   epsilon: 0.20701195158665472\n",
      "episode: 659   score: 1 global_step 15759   epsilon: 0.20680503276560924\n",
      "episode: 660   score: 1 global_step 15776   epsilon: 0.2064537453241741\n",
      "episode: 661   score: 0 global_step 15790   epsilon: 0.20616489787850006\n",
      "episode: 662   score: 1 global_step 15808   epsilon: 0.20579411632644506\n",
      "episode: 663   score: 1 global_step 15826   epsilon: 0.20542400161419042\n",
      "episode: 664   score: 0 global_step 15880   epsilon: 0.2043176465340901\n",
      "episode: 665   score: 1 global_step 15917   epsilon: 0.20356303041124044\n",
      "episode: 666   score: 0 global_step 15936   epsilon: 0.2031766085490674\n",
      "episode: 667   score: 1 global_step 15952   epsilon: 0.2028517696735772\n",
      "episode: 668   score: 1 global_step 15967   epsilon: 0.20254770492115517\n",
      "episode: 669   score: 1 global_step 15982   epsilon: 0.202244095946732\n",
      "episode: 670   score: 1 global_step 15996   epsilon: 0.2019611381809373\n",
      "episode: 671   score: 1 global_step 16011   epsilon: 0.2016584084409963\n",
      "episode: 672   score: 0 global_step 16031   epsilon: 0.2012554745452975\n",
      "episode: 673   score: 1 global_step 16048   epsilon: 0.20091361380921008\n",
      "episode: 674   score: 0 global_step 16062   epsilon: 0.20063251750815334\n",
      "episode: 675   score: 1 global_step 16079   epsilon: 0.200291714952231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 676   score: 0 global_step 16106   epsilon: 0.19975162976027763\n",
      "episode: 677   score: 0 global_step 16184   epsilon: 0.19819955042173534\n",
      "episode: 678   score: 1 global_step 16202   epsilon: 0.1978430943146182\n",
      "episode: 679   score: 0 global_step 16265   epsilon: 0.1966005388512921\n",
      "episode: 680   score: 1 global_step 16282   epsilon: 0.1962665851783362\n",
      "episode: 681   score: 1 global_step 16293   epsilon: 0.19605079984888435\n",
      "episode: 682   score: 1 global_step 16306   epsilon: 0.1957960866726482\n",
      "episode: 683   score: 1 global_step 16317   epsilon: 0.19558081863285606\n",
      "episode: 684   score: 1 global_step 16333   epsilon: 0.19526812391053625\n",
      "episode: 685   score: 1 global_step 16350   epsilon: 0.19493643353180096\n",
      "episode: 686   score: 1 global_step 16359   epsilon: 0.19476106090236622\n",
      "episode: 687   score: 1 global_step 16370   epsilon: 0.19454693082182803\n",
      "episode: 688   score: 1 global_step 16382   epsilon: 0.1943136028630255\n",
      "episode: 689   score: 1 global_step 16397   epsilon: 0.1940223363996278\n",
      "episode: 690   score: 0 global_step 16414   epsilon: 0.19369276216623693\n",
      "episode: 691   score: 1 global_step 16490   epsilon: 0.19222620382570874\n",
      "episode: 692   score: 0 global_step 16500   epsilon: 0.1920340641006117\n",
      "episode: 693   score: 0 global_step 16510   epsilon: 0.19184211642879986\n",
      "episode: 694   score: 1 global_step 16521   epsilon: 0.19163119558224465\n",
      "episode: 695   score: 1 global_step 16534   epsilon: 0.19138222444552747\n",
      "episode: 696   score: 0 global_step 16542   epsilon: 0.19122917224227787\n",
      "episode: 697   score: 1 global_step 16552   epsilon: 0.1910380291002196\n",
      "episode: 698   score: 1 global_step 16564   epsilon: 0.19080890950837967\n",
      "episode: 699   score: 1 global_step 16581   epsilon: 0.1904847937326277\n",
      "episode: 700   score: 1 global_step 16599   epsilon: 0.19014221239026613\n",
      "episode: 701   score: 1 global_step 16616   epsilon: 0.1898192290933601\n",
      "episode: 702   score: 1 global_step 16627   epsilon: 0.18961053231061953\n",
      "episode: 703   score: 1 global_step 16644   epsilon: 0.1892884521471254\n",
      "episode: 704   score: 1 global_step 16660   epsilon: 0.1889858176638655\n",
      "episode: 705   score: 1 global_step 16676   epsilon: 0.18868366703278686\n",
      "episode: 706   score: 1 global_step 16693   epsilon: 0.18836316128035832\n",
      "episode: 707   score: 1 global_step 16708   epsilon: 0.1880808142340776\n",
      "episode: 708   score: 1 global_step 16718   epsilon: 0.18789281803364416\n",
      "episode: 709   score: 1 global_step 16728   epsilon: 0.1877050097448355\n",
      "episode: 710   score: 1 global_step 16738   epsilon: 0.1875173891798244\n",
      "episode: 711   score: 1 global_step 16752   epsilon: 0.18725503540755928\n",
      "episode: 712   score: 1 global_step 16769   epsilon: 0.18693695638692573\n",
      "episode: 713   score: 1 global_step 16849   epsilon: 0.1854473526144327\n",
      "episode: 714   score: 1 global_step 16864   epsilon: 0.1851693762208781\n",
      "episode: 715   score: 1 global_step 16879   epsilon: 0.18489181650016506\n",
      "episode: 716   score: 1 global_step 16895   epsilon: 0.18459621136043883\n",
      "episode: 717   score: 1 global_step 16907   epsilon: 0.18437481769970382\n",
      "episode: 718   score: 1 global_step 16921   epsilon: 0.1841168606689144\n",
      "episode: 719   score: 1 global_step 16931   epsilon: 0.18393282663874266\n",
      "episode: 720   score: 1 global_step 16944   epsilon: 0.18369385737912552\n",
      "episode: 721   score: 1 global_step 16958   epsilon: 0.18343685307335883\n",
      "episode: 722   score: 1 global_step 16973   epsilon: 0.1831618903190058\n",
      "episode: 723   score: 1 global_step 16987   epsilon: 0.18290563028322673\n",
      "episode: 724   score: 1 global_step 17003   epsilon: 0.18261320065913614\n",
      "episode: 725   score: 1 global_step 17016   epsilon: 0.18237594588436146\n",
      "episode: 726   score: 1 global_step 17028   epsilon: 0.18215721507731086\n",
      "episode: 727   score: 1 global_step 17038   epsilon: 0.1819751398111253\n",
      "episode: 728   score: 1 global_step 17050   epsilon: 0.18175688970691875\n",
      "episode: 729   score: 1 global_step 17059   epsilon: 0.1815933739233975\n",
      "episode: 730   score: 1 global_step 17069   epsilon: 0.181411862244705\n",
      "episode: 731   score: 1 global_step 17080   epsilon: 0.18121240894283314\n",
      "episode: 732   score: 1 global_step 17093   epsilon: 0.18097697410507266\n",
      "episode: 733   score: 1 global_step 17110   epsilon: 0.18066955925475753\n",
      "episode: 734   score: 1 global_step 17125   epsilon: 0.18039874453673269\n",
      "episode: 735   score: 1 global_step 17143   epsilon: 0.1800743026594956\n",
      "episode: 736   score: 1 global_step 17161   epsilon: 0.17975044428150608\n",
      "episode: 737   score: 1 global_step 17177   epsilon: 0.1794630591705613\n",
      "episode: 738   score: 1 global_step 17193   epsilon: 0.17917613353109274\n",
      "episode: 739   score: 0 global_step 17210   epsilon: 0.17887177766183437\n",
      "episode: 740   score: 0 global_step 17229   epsilon: 0.1785322269817593\n",
      "episode: 741   score: 0 global_step 17247   epsilon: 0.17821114198187177\n",
      "episode: 742   score: -1 global_step 17263   epsilon: 0.17792621790830532\n",
      "episode: 743   score: -1 global_step 17343   epsilon: 0.1765084160432044\n",
      "episode: 744   score: -1 global_step 17362   epsilon: 0.17617335171114554\n",
      "episode: 745   score: 1 global_step 17375   epsilon: 0.17594446371876246\n",
      "episode: 746   score: 0 global_step 17387   epsilon: 0.17573344644694697\n",
      "episode: 747   score: 0 global_step 17400   epsilon: 0.17550512998840695\n",
      "episode: 748   score: 0 global_step 17411   epsilon: 0.17531217084428863\n",
      "episode: 749   score: 1 global_step 17433   epsilon: 0.1749268887696933\n",
      "episode: 750   score: 1 global_step 17451   epsilon: 0.17461228786536087\n",
      "episode: 751   score: 1 global_step 17462   epsilon: 0.17442031035666203\n",
      "episode: 752   score: 1 global_step 17478   epsilon: 0.17414144706682017\n",
      "episode: 753   score: 1 global_step 17494   epsilon: 0.17386302962376227\n",
      "episode: 754   score: 1 global_step 17502   epsilon: 0.17372398787197643\n",
      "episode: 755   score: 1 global_step 17520   epsilon: 0.1734115503498027\n",
      "episode: 756   score: 0 global_step 17546   epsilon: 0.17296124345582106\n",
      "episode: 757   score: 1 global_step 17579   epsilon: 0.17239138364481316\n",
      "episode: 758   score: 0 global_step 17590   epsilon: 0.17220184790962598\n",
      "episode: 759   score: 1 global_step 17609   epsilon: 0.17187495869696082\n",
      "episode: 760   score: 1 global_step 17622   epsilon: 0.17165165526397866\n",
      "episode: 761   score: 1 global_step 17639   epsilon: 0.17136008077959877\n",
      "episode: 762   score: 1 global_step 17652   epsilon: 0.17113744628645164\n",
      "episode: 763   score: 1 global_step 17662   epsilon: 0.1709663858314831\n",
      "episode: 764   score: 1 global_step 17672   epsilon: 0.1707954963600129\n",
      "episode: 765   score: 1 global_step 17687   epsilon: 0.17053948237305538\n",
      "episode: 766   score: -1 global_step 17703   epsilon: 0.17026682375316626\n",
      "episode: 767   score: 1 global_step 17720   epsilon: 0.16997760159992528\n",
      "episode: 768   score: 1 global_step 17733   epsilon: 0.16975676325177322\n",
      "episode: 769   score: 1 global_step 17746   epsilon: 0.16953621182128298\n",
      "episode: 770   score: 1 global_step 17757   epsilon: 0.16934981520522824\n",
      "episode: 771   score: 1 global_step 17772   epsilon: 0.16909596822269532\n",
      "episode: 772   score: 1 global_step 17784   epsilon: 0.16889316462697437\n",
      "episode: 773   score: 1 global_step 17798   epsilon: 0.16865686782781622\n",
      "episode: 774   score: 1 global_step 17813   epsilon: 0.1684040595390699\n",
      "episode: 775   score: 1 global_step 17828   epsilon: 0.16815163019742307\n",
      "episode: 776   score: 1 global_step 17839   epsilon: 0.16796675585986312\n",
      "episode: 777   score: 1 global_step 17851   epsilon: 0.1677653065739458\n",
      "episode: 778   score: 1 global_step 17867   epsilon: 0.16749708330787733\n",
      "episode: 779   score: 1 global_step 17881   epsilon: 0.16726273975263994\n",
      "episode: 780   score: 1 global_step 17894   epsilon: 0.16704542860807337\n",
      "episode: 781   score: 1 global_step 17907   epsilon: 0.16682839979855418\n",
      "episode: 782   score: 0 global_step 17921   epsilon: 0.1665949917919712\n",
      "episode: 783   score: 1 global_step 17935   epsilon: 0.16636191034428113\n",
      "episode: 784   score: 1 global_step 17948   epsilon: 0.1661457695755561\n",
      "episode: 785   score: 1 global_step 17963   epsilon: 0.16589672529867713\n",
      "episode: 786   score: 1 global_step 17974   epsilon: 0.16571433011668005\n",
      "episode: 787   score: 1 global_step 17988   epsilon: 0.16548248079425368\n",
      "episode: 788   score: 0 global_step 18002   epsilon: 0.16525095584998023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 789   score: 1 global_step 18014   epsilon: 0.16505276373224412\n",
      "episode: 790   score: 1 global_step 18026   epsilon: 0.1648548093142861\n",
      "episode: 791   score: 1 global_step 18038   epsilon: 0.16465709231102318\n",
      "episode: 792   score: 1 global_step 18049   epsilon: 0.16447606004371884\n",
      "episode: 793   score: 1 global_step 18062   epsilon: 0.16426236940996045\n",
      "episode: 794   score: 1 global_step 18078   epsilon: 0.16399974664179084\n",
      "episode: 795   score: 1 global_step 18092   epsilon: 0.16377029617658231\n",
      "episode: 796   score: 1 global_step 18103   epsilon: 0.1635902388974343\n",
      "episode: 797   score: 1 global_step 18116   epsilon: 0.16337769914047884\n",
      "episode: 798   score: 1 global_step 18130   epsilon: 0.16314911897593526\n",
      "episode: 799   score: 1 global_step 18144   epsilon: 0.1629208586156973\n",
      "episode: 800   score: 1 global_step 18162   epsilon: 0.16262785020620915\n",
      "episode: 801   score: 1 global_step 18180   epsilon: 0.16233536876379426\n",
      "episode: 802   score: 1 global_step 18195   epsilon: 0.16209203608894537\n",
      "episode: 803   score: 1 global_step 18208   epsilon: 0.16188144282747122\n",
      "episode: 804   score: 1 global_step 18222   epsilon: 0.16165495606071711\n",
      "episode: 805   score: 1 global_step 18235   epsilon: 0.16144493066248217\n",
      "episode: 806   score: 1 global_step 18248   epsilon: 0.16123517813350516\n",
      "episode: 807   score: 1 global_step 18261   epsilon: 0.16102569811926887\n",
      "episode: 808   score: 0 global_step 18277   epsilon: 0.16076825014297064\n",
      "episode: 809   score: 1 global_step 18292   epsilon: 0.16052726650129123\n",
      "episode: 810   score: 1 global_step 18304   epsilon: 0.16033473969417752\n",
      "episode: 811   score: 1 global_step 18318   epsilon: 0.16011041690487302\n",
      "episode: 812   score: 1 global_step 18330   epsilon: 0.15991839004224598\n",
      "episode: 813   score: 1 global_step 18348   epsilon: 0.15963078148486226\n",
      "episode: 814   score: 1 global_step 18359   epsilon: 0.15945527539582496\n",
      "episode: 815   score: 0 global_step 18374   epsilon: 0.15921625983824006\n",
      "episode: 816   score: 1 global_step 18386   epsilon: 0.15902530537414597\n",
      "episode: 817   score: 1 global_step 18398   epsilon: 0.15883457992942088\n",
      "episode: 818   score: 1 global_step 18410   epsilon: 0.1586440832293926\n",
      "episode: 819   score: 1 global_step 18423   epsilon: 0.15843796961821852\n",
      "episode: 820   score: 1 global_step 18436   epsilon: 0.15823212379402918\n",
      "episode: 821   score: 1 global_step 18448   epsilon: 0.15804234964387487\n",
      "episode: 822   score: 1 global_step 18459   epsilon: 0.15786858995648717\n",
      "episode: 823   score: 1 global_step 18471   epsilon: 0.15767925180708556\n",
      "episode: 824   score: 1 global_step 18490   epsilon: 0.15737993070744258\n",
      "episode: 825   score: 1 global_step 18508   epsilon: 0.15709688749508932\n",
      "episode: 826   score: 1 global_step 18526   epsilon: 0.15681435332769303\n",
      "episode: 827   score: 1 global_step 18544   epsilon: 0.15653232728975128\n",
      "episode: 828   score: 1 global_step 18562   epsilon: 0.15625080846740796\n",
      "episode: 829   score: 0 global_step 18583   epsilon: 0.15592300968860417\n",
      "episode: 830   score: 1 global_step 18604   epsilon: 0.15559589859929418\n",
      "episode: 831   score: 1 global_step 18621   epsilon: 0.15533159707632932\n",
      "episode: 832   score: 1 global_step 18639   epsilon: 0.15505223773223237\n",
      "episode: 833   score: -3 global_step 18718   epsilon: 0.15383208997547823\n",
      "episode: 834   score: 1 global_step 18728   epsilon: 0.15367832709148668\n",
      "episode: 835   score: 1 global_step 18739   epsilon: 0.15350936542941407\n",
      "episode: 836   score: 1 global_step 18752   epsilon: 0.15330992294776818\n",
      "episode: 837   score: 1 global_step 18766   epsilon: 0.15309542851188174\n",
      "episode: 838   score: 1 global_step 18778   epsilon: 0.15291181500697687\n",
      "episode: 839   score: 1 global_step 18791   epsilon: 0.1527131488749617\n",
      "episode: 840   score: 1 global_step 18806   epsilon: 0.15248423943099196\n",
      "episode: 841   score: 1 global_step 18819   epsilon: 0.15228612881383888\n",
      "episode: 842   score: 1 global_step 18832   epsilon: 0.15208827558601848\n",
      "episode: 843   score: 1 global_step 18847   epsilon: 0.15186030279614945\n",
      "episode: 844   score: 1 global_step 18861   epsilon: 0.15164783650984848\n",
      "episode: 845   score: 1 global_step 18877   epsilon: 0.1514053818639413\n",
      "episode: 846   score: 1 global_step 18889   epsilon: 0.15122379529995492\n",
      "episode: 847   score: 1 global_step 18900   epsilon: 0.15105753227326543\n",
      "episode: 848   score: 1 global_step 18910   epsilon: 0.15090654269875797\n",
      "episode: 849   score: 1 global_step 18919   epsilon: 0.15077078112401018\n",
      "episode: 850   score: 1 global_step 18937   epsilon: 0.1504996242742993\n",
      "episode: 851   score: 0 global_step 18958   epsilon: 0.1501838909124598\n",
      "episode: 852   score: 0 global_step 18981   epsilon: 0.14983884766276245\n",
      "episode: 853   score: 1 global_step 19011   epsilon: 0.1493899823108262\n",
      "episode: 854   score: 1 global_step 19025   epsilon: 0.14918097222611193\n",
      "episode: 855   score: 1 global_step 19039   epsilon: 0.14897225456539315\n",
      "episode: 856   score: 1 global_step 19052   epsilon: 0.14877870679022132\n",
      "episode: 857   score: 1 global_step 19065   epsilon: 0.14858541047624527\n",
      "episode: 858   score: 1 global_step 19075   epsilon: 0.14843689191137663\n",
      "episode: 859   score: 1 global_step 19085   epsilon: 0.14828852179825733\n",
      "episode: 860   score: 1 global_step 19098   epsilon: 0.1480958623425667\n",
      "episode: 861   score: 1 global_step 19108   epsilon: 0.1479478331055938\n",
      "episode: 862   score: 1 global_step 19117   epsilon: 0.1478147333045929\n",
      "episode: 863   score: 1 global_step 19132   epsilon: 0.14759316634287048\n",
      "episode: 864   score: 1 global_step 19146   epsilon: 0.14738667016606272\n",
      "episode: 865   score: 1 global_step 19160   epsilon: 0.1471804628960661\n",
      "episode: 866   score: 1 global_step 19175   epsilon: 0.146959846674261\n",
      "episode: 867   score: 1 global_step 19187   epsilon: 0.14678359181942677\n",
      "episode: 868   score: 1 global_step 19202   epsilon: 0.14656357048770258\n",
      "episode: 869   score: 1 global_step 19213   epsilon: 0.1464024311459517\n",
      "episode: 870   score: 1 global_step 19227   epsilon: 0.14619760091528397\n",
      "episode: 871   score: 1 global_step 19242   epsilon: 0.14597845795489203\n",
      "episode: 872   score: 1 global_step 19254   epsilon: 0.1458033801190204\n",
      "episode: 873   score: 1 global_step 19269   epsilon: 0.14558482807607032\n",
      "episode: 874   score: 1 global_step 19281   epsilon: 0.14541022233634415\n",
      "episode: 875   score: 1 global_step 19295   epsilon: 0.14520678029546083\n",
      "episode: 876   score: 1 global_step 19305   epsilon: 0.14506163884079476\n",
      "episode: 877   score: 1 global_step 19335   epsilon: 0.14462708435384847\n",
      "episode: 878   score: 1 global_step 19348   epsilon: 0.14443918191196126\n",
      "episode: 879   score: 1 global_step 19362   epsilon: 0.14423709844437868\n",
      "episode: 880   score: 1 global_step 19374   epsilon: 0.14406410909100542\n",
      "episode: 881   score: 1 global_step 19384   epsilon: 0.14392010979347883\n",
      "episode: 882   score: 1 global_step 19397   epsilon: 0.14373312586728212\n",
      "episode: 883   score: 1 global_step 19412   epsilon: 0.14351767703288446\n",
      "episode: 884   score: 1 global_step 19424   epsilon: 0.1433455505105451\n",
      "episode: 885   score: 1 global_step 19435   epsilon: 0.14318794922138903\n",
      "episode: 886   score: 1 global_step 19448   epsilon: 0.14300191653306016\n",
      "episode: 887   score: 1 global_step 19463   epsilon: 0.14278756374522664\n",
      "episode: 888   score: 1 global_step 19476   epsilon: 0.14260205124583056\n",
      "episode: 889   score: 0 global_step 19489   epsilon: 0.14241677976803696\n",
      "episode: 890   score: 1 global_step 19505   epsilon: 0.14218908374081635\n",
      "episode: 891   score: 1 global_step 19517   epsilon: 0.1420185506538481\n",
      "episode: 892   score: 1 global_step 19529   epsilon: 0.14184822209406986\n",
      "episode: 893   score: 1 global_step 19541   epsilon: 0.141678097816184\n",
      "episode: 894   score: 1 global_step 19558   epsilon: 0.14143743763580216\n",
      "episode: 895   score: 1 global_step 19600   epsilon: 0.14084461655195007\n",
      "episode: 896   score: 1 global_step 19617   epsilon: 0.14060537215674948\n",
      "episode: 897   score: 1 global_step 19674   epsilon: 0.13980616148863076\n",
      "episode: 898   score: 1 global_step 19683   epsilon: 0.1396803862617672\n",
      "episode: 899   score: 1 global_step 19694   epsilon: 0.13952681463804908\n",
      "episode: 900   score: 1 global_step 19706   epsilon: 0.13935947451749212\n",
      "episode: 901   score: 1 global_step 19717   epsilon: 0.13920625572024414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 902   score: 1 global_step 19727   epsilon: 0.13906711209063718\n",
      "episode: 903   score: 1 global_step 19737   epsilon: 0.13892810754206186\n",
      "episode: 904   score: 1 global_step 19747   epsilon: 0.13878924193549977\n",
      "episode: 905   score: 1 global_step 19757   epsilon: 0.13865051513207136\n",
      "episode: 906   score: 1 global_step 19770   epsilon: 0.1384703775701573\n",
      "episode: 907   score: 1 global_step 19783   epsilon: 0.138290474046618\n",
      "episode: 908   score: 1 global_step 19793   epsilon: 0.13815224578669277\n",
      "episode: 909   score: 1 global_step 19806   epsilon: 0.13797275558642014\n",
      "episode: 910   score: 1 global_step 19815   epsilon: 0.13784862976499637\n",
      "episode: 911   score: 1 global_step 19825   epsilon: 0.13771084315057586\n",
      "episode: 912   score: 1 global_step 19837   epsilon: 0.13754568099766212\n",
      "episode: 913   score: 1 global_step 19847   epsilon: 0.1374081971957183\n",
      "episode: 914   score: 1 global_step 19858   epsilon: 0.13725712373064367\n",
      "episode: 915   score: 1 global_step 19868   epsilon: 0.13711992835615078\n",
      "episode: 916   score: 1 global_step 19879   epsilon: 0.13696917182829937\n",
      "episode: 917   score: 1 global_step 19891   epsilon: 0.13680489919163238\n",
      "episode: 918   score: 1 global_step 19902   epsilon: 0.13665448902264793\n",
      "episode: 919   score: 1 global_step 19913   epsilon: 0.13650424422214855\n",
      "episode: 920   score: 1 global_step 19925   epsilon: 0.13634052919185893\n",
      "episode: 921   score: 1 global_step 19937   epsilon: 0.1361770105115898\n",
      "episode: 922   score: 1 global_step 19949   epsilon: 0.1360136879458507\n",
      "episode: 923   score: 1 global_step 19999   epsilon: 0.13533528301106\n",
      "episode: 924   score: 0 global_step 20025   epsilon: 0.13498385076323155\n",
      "episode: 925   score: 0 global_step 20076   epsilon: 0.13429715136076775\n",
      "episode: 926   score: 1 global_step 20093   epsilon: 0.1340690287562902\n",
      "episode: 927   score: 1 global_step 20103   epsilon: 0.13393502004251137\n",
      "episode: 928   score: 0 global_step 20119   epsilon: 0.13372088465748816\n",
      "episode: 929   score: 1 global_step 20133   epsilon: 0.13353379705631163\n",
      "episode: 930   score: 0 global_step 20150   epsilon: 0.1333069711165087\n",
      "episode: 931   score: 0 global_step 20163   epsilon: 0.13313377599537843\n",
      "episode: 932   score: -1 global_step 20190   epsilon: 0.13277478171056192\n",
      "episode: 933   score: 0 global_step 20199   epsilon: 0.13265533219479242\n",
      "episode: 934   score: 0 global_step 20211   epsilon: 0.1324962333195003\n",
      "episode: 935   score: -2 global_step 20221   epsilon: 0.13236379669358905\n",
      "episode: 936   score: -1 global_step 20233   epsilon: 0.1322050474685491\n",
      "episode: 937   score: 0 global_step 20243   epsilon: 0.13207290189749007\n",
      "episode: 938   score: -1 global_step 20252   epsilon: 0.13195408382093457\n",
      "episode: 939   score: 0 global_step 20260   epsilon: 0.13184855749363278\n",
      "episode: 940   score: 1 global_step 20269   epsilon: 0.13172994124629558\n",
      "episode: 941   score: 0 global_step 20278   epsilon: 0.13161143171088915\n",
      "episode: 942   score: 1 global_step 20287   epsilon: 0.13149302879141106\n",
      "episode: 943   score: 0 global_step 20295   epsilon: 0.13138787117906334\n",
      "episode: 944   score: 1 global_step 20314   epsilon: 0.13113845876981894\n",
      "episode: 945   score: 1 global_step 20360   epsilon: 0.1305365771539825\n",
      "episode: 946   score: 1 global_step 20390   epsilon: 0.1301455347270102\n",
      "episode: 947   score: 0 global_step 20480   epsilon: 0.12897942198683318\n",
      "episode: 948   score: 0 global_step 20500   epsilon: 0.12872170805678726\n",
      "episode: 949   score: 1 global_step 20522   epsilon: 0.12843881744807067\n",
      "episode: 950   score: 1 global_step 20533   epsilon: 0.12829760536903922\n",
      "episode: 951   score: 0 global_step 20542   epsilon: 0.12818218370056966\n",
      "episode: 952   score: 1 global_step 20550   epsilon: 0.1280796738374434\n",
      "episode: 953   score: 1 global_step 20558   epsilon: 0.12797724595351057\n",
      "episode: 954   score: 1 global_step 20573   epsilon: 0.12778541440247645\n",
      "episode: 955   score: 0 global_step 20585   epsilon: 0.12763215621546053\n",
      "episode: 956   score: 0 global_step 20620   epsilon: 0.12718620224535152\n",
      "episode: 957   score: 0 global_step 20717   epsilon: 0.1259583991648008\n",
      "episode: 958   score: 0 global_step 20733   epsilon: 0.12575701680570242\n",
      "episode: 959   score: 1 global_step 20745   epsilon: 0.1256061913575064\n",
      "episode: 960   score: 1 global_step 20756   epsilon: 0.1254680936096975\n",
      "episode: 961   score: 1 global_step 20765   epsilon: 0.12535521748342474\n",
      "episode: 962   score: 0 global_step 20775   epsilon: 0.1252299186607492\n",
      "episode: 963   score: 0 global_step 20785   epsilon: 0.1251047450805269\n",
      "episode: 964   score: 1 global_step 20801   epsilon: 0.1249047275440563\n",
      "episode: 965   score: 1 global_step 20814   epsilon: 0.12474244878822267\n",
      "episode: 966   score: 0 global_step 20833   epsilon: 0.12450565132428544\n",
      "episode: 967   score: 0 global_step 20851   epsilon: 0.12428173154398975\n",
      "episode: 968   score: 1 global_step 20867   epsilon: 0.12408302984202209\n",
      "episode: 969   score: 1 global_step 20879   epsilon: 0.12393421207371927\n",
      "episode: 970   score: 0 global_step 20891   epsilon: 0.12378557278855139\n",
      "episode: 971   score: 1 global_step 20903   epsilon: 0.12363711177245648\n",
      "episode: 972   score: 1 global_step 20915   epsilon: 0.12348882881162927\n",
      "episode: 973   score: 1 global_step 20948   epsilon: 0.12308196702431705\n",
      "episode: 974   score: 1 global_step 20959   epsilon: 0.12294664453536769\n",
      "episode: 975   score: 1 global_step 20969   epsilon: 0.12282375320207138\n",
      "episode: 976   score: 1 global_step 20984   epsilon: 0.12263964648134111\n",
      "episode: 977   score: 1 global_step 20995   epsilon: 0.12250481030178573\n",
      "episode: 978   score: 1 global_step 21009   epsilon: 0.12233341500216112\n",
      "episode: 979   score: 1 global_step 21022   epsilon: 0.12217447694774342\n",
      "episode: 980   score: 1 global_step 21033   epsilon: 0.12204015219890846\n",
      "episode: 981   score: 1 global_step 21045   epsilon: 0.12189378453592743\n",
      "episode: 982   score: 1 global_step 21062   epsilon: 0.12168673079490457\n",
      "episode: 983   score: 1 global_step 21078   epsilon: 0.12149217798158725\n",
      "episode: 984   score: 1 global_step 21090   epsilon: 0.12134646752612452\n",
      "episode: 985   score: 0 global_step 21106   epsilon: 0.12115245872591185\n",
      "episode: 986   score: 0 global_step 21125   epsilon: 0.12092247610768728\n",
      "episode: 987   score: 1 global_step 21140   epsilon: 0.12074121930712248\n",
      "episode: 988   score: 1 global_step 21153   epsilon: 0.12058434986565093\n",
      "episode: 989   score: 1 global_step 21167   epsilon: 0.12041564146371676\n",
      "episode: 990   score: 1 global_step 21184   epsilon: 0.12021109855664687\n",
      "episode: 991   score: 1 global_step 21201   epsilon: 0.1200069030944797\n",
      "episode: 992   score: 1 global_step 21216   epsilon: 0.11982701869249948\n",
      "episode: 993   score: 1 global_step 21231   epsilon: 0.11964740392832544\n",
      "episode: 994   score: 1 global_step 21246   epsilon: 0.11946805839778385\n",
      "episode: 995   score: 1 global_step 21257   epsilon: 0.11933670922127014\n",
      "episode: 996   score: 1 global_step 21268   epsilon: 0.11920550445663022\n",
      "episode: 997   score: 1 global_step 21281   epsilon: 0.11905063024704582\n",
      "episode: 998   score: 1 global_step 21295   epsilon: 0.118884067657451\n",
      "episode: 999   score: 1 global_step 21311   epsilon: 0.11869399574352682\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from environment import Env\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "EPISODES = 1000\n",
    "\n",
    "\n",
    "# 그리드월드 예제에서의 딥살사 에이전트\n",
    "class DeepSARSAgent:\n",
    "    def __init__(self):\n",
    "        self.load_model = False\n",
    "        # 에이전트가 가능한 모든 행동 정의\n",
    "        self.action_space = [0, 1, 2, 3, 4]\n",
    "        # 상태의 크기와 행동의 크기 정의\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.state_size = 15\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        self.epsilon = 1.  # exploration\n",
    "        self.epsilon_decay = .9999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.epsilon = 0.05\n",
    "            self.model.load_weights('./save_model/deep_sarsa_trained.h5')\n",
    "\n",
    "    # 상태가 입력 큐함수가 출력인 인공신경망 생성\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(30, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # 입실론 탐욕 방법으로 행동 선택\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # 무작위 행동 반환\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            # 모델로부터 행동 산출\n",
    "            state = np.float32(state)\n",
    "            q_values = self.model.predict(state)\n",
    "            return np.argmax(q_values[0])\n",
    "\n",
    "    def train_model(self, state, action, reward, next_state, next_action, done):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        state = np.float32(state)\n",
    "        next_state = np.float32(next_state)\n",
    "        target = self.model.predict(state)[0]\n",
    "        # 살사의 큐함수 업데이트 식\n",
    "        if done:\n",
    "            target[action] = reward\n",
    "        else:\n",
    "            target[action] = (reward + self.discount_factor *\n",
    "                              self.model.predict(next_state)[0][next_action])\n",
    "\n",
    "        # 출력 값 reshape\n",
    "        target = np.reshape(target, [1, 5])\n",
    "        # 인공신경망 업데이트\n",
    "        self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 환경과 에이전트 생성\n",
    "    env = Env()\n",
    "    agent = DeepSARSAgent()\n",
    "\n",
    "    global_step = 0\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, 15])\n",
    "\n",
    "        while not done:\n",
    "            # env 초기화\n",
    "            global_step += 1\n",
    "\n",
    "            # 현재 상태에 대한 행동 선택\n",
    "            action = agent.get_action(state)\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행 후 샘플 수집\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, 15])\n",
    "            next_action = agent.get_action(next_state)\n",
    "            # 샘플로 모델 학습\n",
    "            agent.train_model(state, action, reward, next_state, next_action,\n",
    "                              done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            state = copy.deepcopy(next_state)\n",
    "\n",
    "            if done:\n",
    "                # 에피소드마다 학습 결과 출력\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./save_graph/deep_sarsa_.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score, \"global_step\",\n",
    "                      global_step, \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "        # 100 에피소드마다 모델 저장\n",
    "        if e % 100 == 0:\n",
    "            agent.model.save_weights(\"./save_model/deep_sarsa.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff43f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
